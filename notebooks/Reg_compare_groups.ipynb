{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reg Compare Groups (with Arianna)\n",
    "- Show the contribution of various properties (H3K27me3 target, TF, CTS) to the RNA decay rate in a linear model\n",
    "- Add labels Beta0 - Beta7 to indicate which group is being shown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import itertools\n",
    "import random\n",
    "import math\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from scipy.stats.mstats import winsorize\n",
    "from collections import defaultdict\n",
    "\n",
    "sys.path.append('../scripts')\n",
    "from plot_helpers import *\n",
    "from utilities import load_dataset\n",
    "from matplotlib import lines\n",
    "from plotting_fxns import Connector, PrettyBox\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdir = '../Figures/Reg/'\n",
    "os.makedirs(outdir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "# log-transform and winsorize the deg_rates\n",
    "# rate_df = load_dataset('../Figures/summary_files/INSPEcT_rates.csv', '../Figures/summary_files/brain4sU_passed.csv')\n",
    "df = pd.read_csv('../Figures/Devreg/gene_cat_me3.csv', index_col='gene')\n",
    "df['me3'] = df['category'] == 'updowngene'\n",
    "df['log_deg'] = df['deg_rate'].apply(np.log10)\n",
    "df['log_deg_wins_1'] = winsorize(df['log_deg'], (0.01, 0.01))\n",
    "target_column = 'log_deg_wins_1'\n",
    "predictors = ['TF', 'me3', 'CTS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the log transformed and untransformed decay rates\n",
    "\n",
    "# Untransformed\n",
    "fig = plt.figure(figsize=(dfig, dfig), constrained_layout=True)\n",
    "ax = fig.add_subplot(111)\n",
    "ax = sns.histplot(data=df, x='deg_rate', color = color_dict['grey'], label='decay rate\\n(1 / TPM)', element='step')\n",
    "ax.set_ylabel('number of genes')\n",
    "ax.set_xlabel('decay rate (1 / TPM)')\n",
    "# ax.set_xlabel('log'r'$_{10}$'' rate')\n",
    "plt.savefig('%s.%s' % (os.path.join(outdir, 'decay_rate_untransformed'), out_fmt), dpi = out_dpi)\n",
    "\n",
    "# Log10-transformed\n",
    "fig = plt.figure(figsize=(dfig, dfig), constrained_layout=True)\n",
    "ax = fig.add_subplot(111)\n",
    "ax = sns.histplot(data=df, x='log_deg_wins_1', color = color_dict['grey'], label='decay rate\\n(1 / TPM)', element='step')\n",
    "ax.set_ylabel('number of genes')\n",
    "ax.set_xlabel('decay rate log'r'$_{10}$'' (1 / TPM)')\n",
    "plt.savefig('%s.%s' % (os.path.join(outdir, 'decay_rate_transformed'), out_fmt), dpi = out_dpi)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part I: Qualitative assessment of the factor combinations\n",
    "1) Find all possible combinations of factors -- assign combinations to different groups\n",
    "2) Plot the decay rates of all groups\n",
    "3) Plot the ratio of decay rate means between groups that differ by only one factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all combinations of groups using PolynomialFeatures()\n",
    "def feat_2_group(arr):\n",
    "    '''\n",
    "    Convert the featurenames_out() to arrays specifying which group they belong to.\n",
    "    nfeats is the number of input features before transformation.\n",
    "    It is understood that 1 = 'intercept', not group 0,0,0\n",
    "    However, I will assign it to group 0,0,0 for convenience, \n",
    "    and this will map Beta0.\n",
    "    '''\n",
    "    n_feats = max([len(i.split(' ')) for i in arr])\n",
    "    group_ids = []\n",
    "    for i in arr:\n",
    "        a = np.zeros(n_feats,).astype(int)\n",
    "        if i == '1':\n",
    "            pass\n",
    "        else:\n",
    "            l = [int(j.lstrip('x')) for j in i.split(' ')]\n",
    "            a[l] = 1\n",
    "        group_ids.append(a)\n",
    "    return group_ids\n",
    "\n",
    "X = df[predictors].values\n",
    "y = df[target_column].values\n",
    "poly = PolynomialFeatures(interaction_only=True, degree=len(predictors))\n",
    "X_tr = poly.fit_transform(X)\n",
    "feat_names = poly.get_feature_names_out()\n",
    "group_ids = feat_2_group(feat_names)\n",
    "# Make dataframe mapping group index -> group labels\n",
    "group_df = pd.DataFrame(group_ids)\n",
    "idx = list(group_df.columns)\n",
    "pred_array = np.array(predictors)\n",
    "group_df['tuple_label'] = group_df[idx].apply(lambda x: f'({\",\".join([str(i) for i in x])})', 1)\n",
    "group_df['beta_label'] = group_df.index.map(lambda x: '$\\\\beta_{%s}$' % x)\n",
    "group_df['str_label'] = group_df[idx].apply(lambda x: ':'.join(np.compress(x, pred_array)), 1)\n",
    "group_df['str_label'] = group_df['str_label'].replace('', 'intercept')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the decay rates for each group of genes\n",
    "group_arr = group_df.iloc[:, 0:len(predictors)].values\n",
    "deg_rates = []\n",
    "for row in group_arr:\n",
    "    # Get degrates for all groups\n",
    "    query_str = '&'.join([f'{pred} == {v}' for (pred,v) in zip(predictors, row)])\n",
    "    deg_rates.append(df.query(query_str)[target_column].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all pairs, store indices\n",
    "passed_pairs = defaultdict(list)\n",
    "ordered_pairs = []\n",
    "for i in itertools.combinations(enumerate(group_arr), 2):\n",
    "    indices = [j[0] for j in i]\n",
    "    comb = [j[1] for j in i]\n",
    "    a = np.array(comb)\n",
    "    sum = a.sum(axis=0)\n",
    "    # Arrays with one difference will have one column that sums to 1.\n",
    "    if np.count_nonzero(sum == 1) == 1:\n",
    "        ordered_pairs.append(indices)\n",
    "        diff_i = np.where(sum == 1)[0][0]\n",
    "        passed_pairs[diff_i].append(indices)\n",
    "        # Double check that directionality is from F -> T, so that we use 0-1 to get the effect of adding one True\n",
    "        assert comb[1].sum() > comb[0].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the decay rates of each group\n",
    "fig = plt.figure(figsize=(dfig*2,dfig*1.5), constrained_layout=True)\n",
    "\n",
    "gs = fig.add_gridspec(ncols=1, nrows=4)\n",
    "ax = fig.add_subplot(gs[1:4,:])\n",
    "ax = PrettyBox(data=deg_rates, fliersize=1, color=color_dict['grey'])\n",
    "ax.set_ylabel('decay rate (log'r'$_{10}$'' 1 / min)')\n",
    "ngenes = [len(i) for i in deg_rates]\n",
    "labels = [f'{l}\\n[{n}]' for (l,n) in zip(group_df['tuple_label'], ngenes)]\n",
    "_ = ax.set_xticklabels(labels)\n",
    "c = Connector(ax)\n",
    "for i in ordered_pairs:\n",
    "    c.add_connector(ax, i)\n",
    "pred_str = f'({\",\".join(predictors)})'\n",
    "ax.text(-0.5, 1, f'{pred_str} 1 = present, 0 = not present')\n",
    "ax.text(-0.5, -3.78, '[num genes]', ha='right', va='top')\n",
    "plt.savefig('%s.%s' % (os.path.join(outdir, 'decay_clusters_boxplot'), out_fmt), dpi = out_dpi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mark the effect of having TF and me3 together, to put an asterix on the plot to indicate these\n",
    "TF_index = np.where(np.array(predictors) == 'TF')[0][0]\n",
    "me3_index = np.where(np.array(predictors) == 'me3')[0][0]\n",
    "CTS_index = np.where(np.array(predictors) == 'CTS')[0][0]\n",
    "for i,l in enumerate(group_arr):\n",
    "    sum = np.sum([l[TF_index], l[me3_index]])\n",
    "    if sum == 2 and np.sum(l) == 2:\n",
    "        double_comp_index = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the ratio of mean decay rates between groups\n",
    "# Decay rates are log10-transformed, so need to subtract\n",
    "ratios = []\n",
    "n = []\n",
    "# 0, 1, 2\n",
    "for pos in sorted(list(passed_pairs.keys())):\n",
    "    pos_ratios = []\n",
    "    pos_genes = []\n",
    "    for pair in passed_pairs[pos]:\n",
    "        i, j = pair\n",
    "        # Effect of True compared to False is index 1 - index 0\n",
    "        ratio = deg_rates[j].mean() - deg_rates[i].mean()\n",
    "        pos_ratios.append(ratio)\n",
    "        pos_genes.append(f'{ngenes[j]} / {ngenes[i]}')\n",
    "        if (double_comp_index in [i, j]) and (pos != CTS_index):\n",
    "            pos_genes[-1] = '*' + pos_genes[-1]\n",
    "    ratios.append(pos_ratios)\n",
    "    n.append(pos_genes)\n",
    "ngenes_a = np.array(n)\n",
    "ratio_a = np.array(ratios)\n",
    "# Convert to base 2 to conform to traditional bio expression change presentation\n",
    "ratio_a_log2 = ratio_a/math.log(2, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the ratio of decay rate means between groups\n",
    "# Get the range of the data and make symmetrical so that red=+ve and blue=-ve\n",
    "max_val = abs(max(ratio_a_log2.min(), ratio_a_log2.max(), key=abs))\n",
    "max_pos = (max_val//0.1)*0.1 + 0.1\n",
    "max_neg = -max_pos\n",
    "nrows = ratio_a.shape[0]\n",
    "fig = plt.figure(figsize=(dfig*2, dfig*1.5))\n",
    "gs = fig.add_gridspec(ncols=20, nrows=nrows, hspace=0.5)\n",
    "# cbar_ax = fig.add_subplot(gs[:,-1])\n",
    "cbar_ax = fig.add_subplot(gs[:,-2])\n",
    "for i in range(nrows):\n",
    "    # ax = fig.add_subplot(gs[i,:-1])\n",
    "    ax = fig.add_subplot(gs[i,:-2])\n",
    "    if i == 0:\n",
    "        # ax = sns.heatmap(ratio_a[i].reshape(1,-1), vmin=-0.5, vmax=0.5, cmap='seismic', cbar_ax=cbar_ax, cbar_kws={'label':'effect of adding factor (log'r'$_{10}$'')'})\n",
    "        # ax = sns.heatmap(ratio_a[i].reshape(1,-1), vmin=max_neg, vmax=max_pos, cmap='seismic', cbar_ax=cbar_ax, cbar_kws={'label':'+factor / -factor (log'r'$_{10}$'' mean / mean)'},\n",
    "        ax = sns.heatmap(ratio_a_log2[i].reshape(1,-1), vmin=max_neg, vmax=max_pos, cmap='seismic', cbar_ax=cbar_ax, cbar_kws={'label':'ratio of group means (log'r'$_{2}$'' mean / mean)'},\n",
    "                         annot=ngenes_a[i].reshape(1,-1), fmt='')\n",
    "    else:\n",
    "        ax = sns.heatmap(ratio_a_log2[i].reshape(1,-1), vmin=max_neg, vmax=max_pos, cmap='seismic', cbar=False, annot=ngenes_a[i].reshape(1,-1), fmt='')\n",
    "    ax.set_yticklabels([predictors[i]])\n",
    "    # We should actually put thi the other way around to make it match with the +factor/-factor\n",
    "    label_a = np.array(group_df['tuple_label'])[passed_pairs[i]]\n",
    "    col1 = label_a[:, 0].reshape(-1, 1)\n",
    "    col2 = label_a[:, 1].reshape(-1, 1)\n",
    "    label_a2 = np.hstack([col2, col1])\n",
    "    xlabels = np.apply_along_axis(lambda x: ' / '.join(x), 1, label_a2)\n",
    "    ax.set_xticklabels(xlabels, fontsize=6)\n",
    "fig.text(0.007, 0.5, 'feature varying between groups:', rotation=90, va='center', ha='left')\n",
    "fig.text(0.5, 0.9, 'n genes / n genes', ha='center', va='bottom')\n",
    "# fig.text(0.5, 0.01, 'group ID (0 = false, 1 = true for: TF, me3, CTS)', ha='center', va='bottom')\n",
    "plt.savefig('%s.%s' % (os.path.join(outdir, 'TrueFalse_comp'), out_fmt), dpi = out_dpi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part II: Bootstrapping to get more accurate coefficients with the given group sizes\n",
    "1) Find size of smallest group (N)\n",
    "2) Choose random seed\n",
    "3) Sample the N from each of the groups with replacement\n",
    "4) Run 10,000 times (bootstraps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_OLS(df, target_column, predictors, interactions=False):\n",
    "    '''\n",
    "    Run linear regression on the data given a target column and predictors.\n",
    "    Use statsmodels.ols and pass in a dataframe with either the actual predictor names\n",
    "    or a betas, which need to be specified via another mapping df.\n",
    "    beta_df = df with integer labelled columns corresponding to the predictors (i.e. [0,1,2]),\n",
    "    1/0 in each row and a column called 'beta_label'.\n",
    "    '''\n",
    "    X = df[predictors].values\n",
    "    y = df[target_column].values\n",
    "    n_comb = 2**len(predictors)\n",
    "    # Betas should map to the same combinations in group_df since these were extracted with PolynomialFeatures()\n",
    "    betas = ['$\\\\beta_{%s}$' % i for i in range(n_comb)]\n",
    "    \n",
    "    if interactions:\n",
    "        poly = PolynomialFeatures(interaction_only=True, degree=len(predictors))\n",
    "        # When using PolynomialFeatures, it already adds a constant.\n",
    "        X_tr = poly.fit_transform(X)\n",
    "        Xt = pd.DataFrame(X_tr, columns=betas)\n",
    "        mod = sm.OLS(y, Xt)\n",
    "        res = mod.fit()\n",
    "        res.summary()\n",
    "    else:\n",
    "        X1 = sm.add_constant(X.astype(int))\n",
    "        X1 = pd.DataFrame(X1, columns=betas[0:len(predictors)+1])\n",
    "        mod = sm.OLS(y, X1)\n",
    "        res = mod.fit()\n",
    "        res.summary()\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the linear regression coefficients and pvalues via bootstrapping\n",
    "def run_bootstrap(rates, group_arr, samp_n=30, seed_num=0, shuffle=False):\n",
    "    '''\n",
    "    Select a random sample from each of the groups.\n",
    "    rates = a list of arrays, ordered by group\n",
    "    group_arr = an array of shape (num_groups, num_predictors) with 0/1 to show membership\n",
    "    samp_n = number of samples to take from each group\n",
    "    returns group_samp_arr = array of shape (samp_n*len(rates), num_predictors + 1)\n",
    "    '''\n",
    "    group_rates = []\n",
    "    np.random.seed(seed_num)\n",
    "    predictors_n = group_arr.shape[1]\n",
    "    for j in range(len(rates)):\n",
    "        a = np.random.randint(0, len(rates[j]), size=samp_n)\n",
    "        samp = np.take(rates[j], a).reshape(-1,1)\n",
    "        # Add in predictor columns\n",
    "        arr = np.broadcast_to(group_arr[j], (samp_n, predictors_n))\n",
    "        group_rates.append(np.hstack([samp, arr]))\n",
    "    group_samp_arr = np.vstack(group_rates)\n",
    "    if shuffle:\n",
    "        np.random.shuffle(group_samp_arr)\n",
    "    return group_samp_arr\n",
    "\n",
    "samp_n = min(ngenes)\n",
    "bootstrap_n = 100 #CHANGE TO 10000 FOR THE FINAL VERSION\n",
    "res_d = {k:{'coeff':[], 'pvalues':[]} for k in ['minus_int', 'plus_int']}\n",
    "coefficients = []\n",
    "pvalues = []\n",
    "for i in range(bootstrap_n):\n",
    "    # random seed will be a multiple of 997 (i+1, so it starts with 997)\n",
    "    # random seed the same for all groups in the same bootstrap iteration\n",
    "    seed_num = 104729*(i+1) + 997*i\n",
    "    group_samp_arr = run_bootstrap(deg_rates, group_arr, samp_n=samp_n, seed_num=seed_num, shuffle=True)\n",
    "    # np.random.seed(seed_num)\n",
    "    # Original, run outside function\n",
    "    # group_rates = []\n",
    "    # for j in range(len(group_arr)):\n",
    "    #     # Get rates here\n",
    "    #     a = np.random.randint(0, len(deg_rates[j]), size=samp_n)\n",
    "    #     samp = np.take(deg_rates[j], a).reshape(-1,1)\n",
    "    #     # Add in predictor columns\n",
    "    #     arr = np.broadcast_to(group_arr[j], (samp_n, len(predictors)))\n",
    "    #     group_rates.append(np.hstack([samp, arr]))\n",
    "    # group_samp_arr = np.vstack(group_rates)\n",
    "    # np.random.shuffle(group_samp_arr)\n",
    "\n",
    "    bdf = pd.DataFrame(group_samp_arr, columns=[target_column] + predictors)\n",
    "    res = run_OLS(bdf, target_column, predictors, interactions=False)\n",
    "    res_int = run_OLS(bdf, target_column, predictors, interactions=True)\n",
    "    res_d['minus_int']['coeff'].append(res.params)\n",
    "    res_d['minus_int']['pvalues'].append(res.pvalues)\n",
    "    res_d['plus_int']['coeff'].append(res_int.params)\n",
    "    res_d['plus_int']['pvalues'].append(res_int.pvalues)\n",
    "\n",
    "res_d['minus_int']['coeff'] = pd.concat(res_d['minus_int']['coeff'], axis=1).transpose()\n",
    "res_d['minus_int']['pvalues'] = pd.concat(res_d['minus_int']['pvalues'], axis=1).transpose()\n",
    "res_d['plus_int']['coeff'] = pd.concat(res_d['plus_int']['coeff'], axis=1).transpose()\n",
    "res_d['plus_int']['pvalues'] = pd.concat(res_d['plus_int']['pvalues'], axis=1).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the coefficients obtained from bootstrapping\n",
    "# Constrained_layout doesnt work well here. \n",
    "fig = plt.figure(figsize=(dfig*2, dfig))\n",
    "gs = fig.add_gridspec(ncols=3, nrows=1, wspace=0.5)\n",
    "# gs.get_subplot_params().bottom\n",
    "ax1 = fig.add_subplot(gs[0])\n",
    "ax1 = PrettyBox(data=res_d['minus_int']['coeff'], fliersize=1, color=color_dict['grey'])\n",
    "ax2 = fig.add_subplot(gs[1:])\n",
    "ax2 = PrettyBox(data=res_d['plus_int']['coeff'], fliersize=1, color=color_dict['grey'])\n",
    "ax1.set_ylabel(f'bootstrap coefficients (N = {bootstrap_n})')\n",
    "# ax.sharey() is not symmetrical, have to call on both otherwise it only takes range of one into account\n",
    "ax1.sharey(ax2)\n",
    "ax2.sharey(ax1)\n",
    "ax1.text(1, 0.25, 'no interactions', va='bottom', ha='right', transform=ax1.transAxes)\n",
    "ax2.text(1, 0.25, '+ interactions', va='bottom', ha='right', transform=ax2.transAxes)\n",
    "ax1.axhline(y=0, linestyle='--', color=color_dict['grey'], zorder=0)\n",
    "ax2.axhline(y=0, linestyle='--', color=color_dict['grey'], zorder=0)\n",
    "plt.subplots_adjust(bottom=0.14, left=0.14, right=0.95)\n",
    "plt.savefig('%s.%s' % (os.path.join(outdir, 'bootstrap_coeffs'), out_fmt), dpi = out_dpi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the pvalues obtained from bootstrapping\n",
    "# Get best min/max values for the split axes\n",
    "# add extra space to min/max\n",
    "def y_limits(df):\n",
    "    border = (df.max().max() - df.min().min())*0.025\n",
    "    beta_0_min = df[df.columns[0]].min() - border\n",
    "    beta_other_min = df[df.columns[1:]].min().min() - border\n",
    "    beta_0_max = df[df.columns[0]].max() + border\n",
    "    beta_other_max = df[df.columns[1:]].max().max() + border\n",
    "    # set anything less than 0 to 0\n",
    "    beta_0_min, beta_other_min, beta_0_max, beta_other_max = list(map(lambda x: 0 if x <0 else x, \n",
    "                                                            [beta_0_min, beta_other_min, beta_0_max, beta_other_max]))\n",
    "    return beta_0_min, beta_other_min, beta_0_max, beta_other_max\n",
    "\n",
    "def diagonal_cuts(top_ax, bottom_ax, d=0.015):\n",
    "    '''\n",
    "    Draw diagonal lines to split the axis.\n",
    "    https://stackoverflow.com/questions/63726234/how-to-draw-a-broken-y-axis-catplot-graphes-with-seaborn\n",
    "    '''\n",
    "    kwargs = dict(transform=top_ax.transAxes, color='k', clip_on=False)\n",
    "    top_ax.plot((-d, +d), (-d, +d), **kwargs)\n",
    "    kwargs.update(transform=bottom_ax.transAxes)\n",
    "    bottom_ax.plot((-d, +d), (1 - d, 1 + d), **kwargs)\n",
    "\n",
    "# Try to split the y-axis since it intercept pvalue is so much larger than others\n",
    "# Constrained_layout doesnt work well here. \n",
    "fig = plt.figure(figsize=(dfig*2, dfig))\n",
    "gs = fig.add_gridspec(ncols=3, nrows=2, wspace=0.5)\n",
    "# gs.get_subplot_params().bottom\n",
    "ax1_top = fig.add_subplot(gs[0,0])\n",
    "ax1_bottom = fig.add_subplot(gs[1,0])\n",
    "ax2_top = fig.add_subplot(gs[0,1:])\n",
    "ax2_bottom = fig.add_subplot(gs[1,1:])\n",
    "# Get best min/maxes for the axes\n",
    "minus_df = -res_d['minus_int']['pvalues'].apply(np.log10)\n",
    "plus_df = -res_d['plus_int']['pvalues'].apply(np.log10)\n",
    "min0a, min1a, max0a, max1a = y_limits(minus_df)\n",
    "min0b, min1b, max0b, max1b = y_limits(plus_df)\n",
    "ymin0 = min(min0a, min0b)\n",
    "ymax0 = max(max0a, max0b)\n",
    "ymin1 = min(min1a, min1b)\n",
    "ymax1 = max(max1a, max1b)\n",
    "ax1_top.set_ylim(ymin0, ymax0)\n",
    "ax2_top.set_ylim(ymin0, ymax0)\n",
    "ax1_bottom.set_ylim(ymin1, ymax1)\n",
    "ax2_bottom.set_ylim(ymin1, ymax1)\n",
    "\n",
    "ax1_top = PrettyBox(data=minus_df, fliersize=1, color=color_dict['grey'], ax=ax1_top)\n",
    "ax1_bottom = PrettyBox(data=minus_df, fliersize=1, color=color_dict['grey'], ax=ax1_bottom)\n",
    "sns.despine(ax=ax1_top, bottom=True)\n",
    "ax1_top.set_xticks([])\n",
    "\n",
    "ax2_top = PrettyBox(data=plus_df, fliersize=1, color=color_dict['grey'], ax=ax2_top)\n",
    "ax2_bottom = PrettyBox(data=plus_df, fliersize=1, color=color_dict['grey'], ax=ax2_bottom)\n",
    "sns.despine(ax=ax2_top, bottom=True)\n",
    "ax2_top.set_xticks([])\n",
    "# the supylabel is placed too close the axis\n",
    "# fig.supylabel(f'Bootstrap p-values (-log'r'$_{10}$'')', fontsize=7)\n",
    "diagonal_cuts(ax1_top, ax1_bottom)\n",
    "diagonal_cuts(ax2_top, ax2_bottom)\n",
    "\n",
    "ax1_top.set_ylabel('pvalues from model')\n",
    "t = ax1_top.yaxis.get_label().get_position()\n",
    "display_to_ax = ax1_top.transAxes.inverted()\n",
    "x_pos, y_pos = display_to_ax.transform(t)\n",
    "ax1_top.set_ylabel('')\n",
    "# set_label_coords() #For some reason doesnt work as expected, puts it further to the left than if using ax.text()\n",
    "# ax1_top.yaxis.set_label_coords(x_pos, 0)\n",
    "# va centers it\n",
    "ax1_top.text(x_pos, -0.1, 'p-values from bootstraps (-log'r'$_{10}$)', transform=ax1_top.transAxes, rotation=90, va='center', ha='right')\n",
    "# ma=center for multiline label\n",
    "pval_co_log10 = -math.log(0.05, 10)\n",
    "ax1_bottom.axhline(y=pval_co_log10, linestyle='--', color=color_dict['grey'], zorder=0)\n",
    "ax2_bottom.axhline(y=pval_co_log10, linestyle='--', color=color_dict['grey'], zorder=0)\n",
    "plt.subplots_adjust(bottom=0.14, left=0.14, right=0.95)\n",
    "plt.savefig('%s.%s' % (os.path.join(outdir, 'bootstrap_pvals'), out_fmt), dpi = out_dpi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As a comparison, plot the coefficents obtained from all data\n",
    "# Get predictor values for each group and merge with the data\n",
    "id_vals = []\n",
    "for j in range(len(group_arr)):\n",
    "    arr = np.broadcast_to(group_arr[j], (len(deg_rates[j]), len(predictors)))\n",
    "    id_vals.append(arr)\n",
    "id_cols = np.vstack(id_vals)\n",
    "vals = np.hstack(deg_rates).reshape(-1,1)\n",
    "big_df = pd.DataFrame(np.hstack([vals, id_cols]), columns=[target_column] + predictors)\n",
    "res = run_OLS(big_df, target_column, predictors, interactions=False)\n",
    "res_int = run_OLS(big_df, target_column, predictors, interactions=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot coefficients for all data\n",
    "fig = plt.figure(figsize=(dfig, dfig), constrained_layout=True)\n",
    "ax = fig.add_subplot(111)\n",
    "res_df = pd.DataFrame(res.params, columns=['val'])\n",
    "res_df['model'] = 'no interactions'\n",
    "res_df2 = pd.DataFrame(res_int.params, columns=['val'])\n",
    "res_df2['model'] = '+ interactions'\n",
    "ax = sns.barplot(data=pd.concat([res_df, res_df2]).reset_index(), x='index', y='val', hue='model', ax=ax)\n",
    "ax.set_ylabel('model coefficients')\n",
    "ax.set_xlabel('')\n",
    "plt.savefig('%s.%s' % (os.path.join(outdir, 'alldata_coeffs'), out_fmt), dpi = out_dpi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot p-values for all data\n",
    "fig = plt.figure(figsize=(dfig, dfig), constrained_layout=True)\n",
    "ax = fig.add_subplot(111)\n",
    "res_df = pd.DataFrame(res.pvalues, columns=['val'])\n",
    "res_df['model'] = 'no interactions'\n",
    "res_df2 = pd.DataFrame(res_int.pvalues, columns=['val'])\n",
    "res_df2['model'] = '+ interactions'\n",
    "res_df3 = pd.concat([res_df, res_df2])\n",
    "res_df3['pval_nlog'] = -res_df3['val'].apply(np.log10)\n",
    "ax = sns.barplot(data=res_df3.reset_index(), x='index', y='pval_nlog', hue='model', ax=ax)\n",
    "ax.legend().remove()\n",
    "ax.set_xlabel('')\n",
    "ax.set_ylabel('p-values for coefficients (-log'r'$_{10}$'')')\n",
    "ax.text(0, 4, 'undefined', rotation=90, ha='center', va='bottom')\n",
    "plt.savefig('%s.%s' % (os.path.join(outdir, 'alldata_pvalues'), out_fmt), dpi = out_dpi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the bootstrap function with different seeds and +/- shuffle\n",
    "def prime_seed(i):\n",
    "    seed = 104729*(i+1) + 997*i\n",
    "    return seed\n",
    "\n",
    "def zero_seed(i):\n",
    "    '''Just returns 0. Doesn't really make sense for multiple iterations as always the same.'''\n",
    "    return 0\n",
    "\n",
    "def test_bootstrap(deg_rates, group_arr, samp_n=samp_n, seed_fxn=prime_seed, bootstrap_n=100, shuffle=False, interactions=False, \n",
    "                   target_column=target_column, predictors=predictors):\n",
    "\n",
    "    res_d = {'pvalues':[], 'coeff':[]}\n",
    "    for i in range(bootstrap_n):\n",
    "        seed_num = seed_fxn(i)\n",
    "        group_samp_arr = run_bootstrap(deg_rates, group_arr, samp_n=samp_n, seed_num=seed_num, shuffle=shuffle)\n",
    "        bdf = pd.DataFrame(group_samp_arr, columns=[target_column] + predictors)\n",
    "        res = run_OLS(bdf, target_column, predictors, interactions=interactions)\n",
    "        res_d['pvalues'].append(res.pvalues)\n",
    "        res_d['coeff'].append(res.params)\n",
    "    \n",
    "    final_res_d = {}\n",
    "    final_res_d['coeff'] = pd.concat(res_d['coeff'], axis=1).transpose()\n",
    "    final_res_d['pvalues'] = pd.concat(res_d['pvalues'], axis=1).transpose()\n",
    "    return final_res_d\n",
    "\n",
    "res_noshuff = test_bootstrap(deg_rates, group_arr, samp_n=samp_n, seed_fxn=prime_seed, shuffle=False, target_column=target_column, predictors=predictors)\n",
    "res_shuff = test_bootstrap(deg_rates, group_arr, samp_n=samp_n, seed_fxn=prime_seed, shuffle=True, target_column=target_column, predictors=predictors)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('pretty')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "bdb49103a4ed208a05ea4530afbe53462c06fafea10c7833b005d674746fdb08"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
