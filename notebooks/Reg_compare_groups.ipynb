{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reg Compare Groups (with Arianna)\n",
    "- Show the contribution of various properties (H3K27me3 target, TF, CTS) to the RNA decay rate in a linear model\n",
    "- Add labels Beta0 - Beta7 to indicate which group is being shown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import itertools\n",
    "import random\n",
    "import math\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from scipy.stats.mstats import winsorize\n",
    "from collections import defaultdict\n",
    "import pickle\n",
    "\n",
    "sys.path.append('../scripts')\n",
    "from plot_helpers import *\n",
    "from utilities import load_dataset\n",
    "from matplotlib import lines\n",
    "from plotting_fxns import Connector, PrettyBox, diagonal_cuts\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdir = '../Figures/Reg/'\n",
    "os.makedirs(outdir, exist_ok=True)\n",
    "# set to True to run_bootstrap or False to look at previously generated results\n",
    "run_bootstrap_fxn = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure out row widths:\n",
    "bottom_width = 4*dfig + 1/25.4\n",
    "top_width = (bottom_width - 2/25.4)/3\n",
    "print('top width', top_width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "# log-transform and winsorize the deg_rates\n",
    "# rate_df = load_dataset('../Figures/summary_files/INSPEcT_rates.csv', '../Figures/summary_files/brain4sU_passed.csv')\n",
    "df = pd.read_csv('../Figures/Devreg/gene_cat_me3.csv', index_col='gene')\n",
    "df['me3'] = df['category'] == 'updowngene'\n",
    "df['deg_rate_wins_1'] = winsorize(df['deg_rate'], (0.01, 0.01))\n",
    "# For the plots with log, log first and then winsorize:\n",
    "df['log_deg'] = df['deg_rate'].apply(np.log10)\n",
    "df['log_deg_wins_1'] = winsorize(df['log_deg'], (0.01, 0.01))\n",
    "target_column = 'deg_rate_wins_1'\n",
    "predictors = ['TF', 'me3', 'CTS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the rates after winsorization\n",
    "# Untransformed rates + winsorization, plotted on logscale\n",
    "fig = plt.figure(figsize=(top_width, dfig), constrained_layout=True)\n",
    "ax = fig.add_subplot(111)\n",
    "# ax = sns.histplot(data=df, x='deg_rate', color = color_dict['grey'], label='decay rate\\n(1 / TPM)', element='step', log_scale=True)\n",
    "# ax = sns.histplot(data=df, x='deg_rate_wins_1', color = color_dict['grey'], label='decay rate\\n(1 / TPM)', element='step', log_scale=True)\n",
    "ax = sns.histplot(data=df, x='log_deg_wins_1', color = color_dict['grey'], label='decay rate\\n(1 / TPM)', element='step')\n",
    "ax.set_ylabel('number of genes')\n",
    "ax.set_xlabel('decay rate log'r'$_{10}$'' (1 / TPM)')\n",
    "plt.savefig('%s.%s' % (os.path.join(outdir, 'decay_rate_logscale'), out_fmt), dpi = out_dpi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part I: Qualitative assessment of the factor combinations\n",
    "1) Find all possible combinations of factors -- assign combinations to different groups\n",
    "2) Plot the decay rates of all groups\n",
    "3) Plot the ratio of decay rate means between groups that differ by only one factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all combinations of groups using PolynomialFeatures()\n",
    "def feat_2_group(arr):\n",
    "    '''\n",
    "    Use the featurenames_out() to generate arrays which will specify all possible combinations of the features.\n",
    "    These arrays will be used to generate the independent gene groups and examine the decay rate differences between these groups.\n",
    "    '''\n",
    "    n_feats = max([len(i.split(' ')) for i in arr])\n",
    "    group_ids = []\n",
    "    for i in arr:\n",
    "        a = np.zeros(n_feats,).astype(int)\n",
    "        if i == '1':\n",
    "            pass\n",
    "        else:\n",
    "            l = [int(j.lstrip('x')) for j in i.split(' ')]\n",
    "            a[l] = 1\n",
    "        group_ids.append(a)\n",
    "    return group_ids\n",
    "\n",
    "X = df[predictors].values\n",
    "y = df[target_column].values\n",
    "poly = PolynomialFeatures(interaction_only=True, degree=len(predictors))\n",
    "X_tr = poly.fit_transform(X)\n",
    "feat_names = poly.get_feature_names_out()\n",
    "group_ids = feat_2_group(feat_names)\n",
    "# Make dataframe mapping group index -> group labels\n",
    "group_df = pd.DataFrame(group_ids)\n",
    "idx = list(group_df.columns)\n",
    "pred_array = np.array(predictors)\n",
    "group_df['tuple_label'] = group_df[idx].apply(lambda x: f'({\",\".join([str(i) for i in x])})', 1)\n",
    "group_df['beta_label'] = group_df.index.map(lambda x: '$\\\\beta_{%s}$' % x)\n",
    "group_df['str_label'] = group_df[idx].apply(lambda x: ':'.join(np.compress(x, pred_array)), 1)\n",
    "group_df['str_label'] = group_df['str_label'].replace('', 'intercept')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the decay rates for each group of genes\n",
    "group_arr = group_df.iloc[:, 0:len(predictors)].values\n",
    "deg_rates = []\n",
    "deg_rates_log = []\n",
    "for row in group_arr:\n",
    "    print('row', row)\n",
    "    # Get degrates for all groups\n",
    "    query_str = '&'.join([f'{pred} == {v}' for (pred,v) in zip(predictors, row)])\n",
    "    print('query str', query_str)\n",
    "    deg_rates.append(df.query(query_str)[target_column].values)\n",
    "    deg_rates_log.append(df.query(query_str)['log_deg_wins_1'].values)\n",
    "# Check that deg_rates is the same length as the original array, which shows that query run correctly\n",
    "assert np.sum([len(i) for i in deg_rates]) == len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all pairs, store indices\n",
    "passed_pairs = defaultdict(list)\n",
    "ordered_pairs = []\n",
    "for i in itertools.combinations(enumerate(group_arr), 2):\n",
    "    indices = [j[0] for j in i]\n",
    "    comb = [j[1] for j in i]\n",
    "    a = np.array(comb)\n",
    "    sum = a.sum(axis=0)\n",
    "    # Arrays with one difference will have one column that sums to 1.\n",
    "    if np.count_nonzero(sum == 1) == 1:\n",
    "        ordered_pairs.append(indices)\n",
    "        diff_i = np.where(sum == 1)[0][0]\n",
    "        passed_pairs[diff_i].append(indices)\n",
    "        # Double check that directionality is from F -> T, so that we use 0-1 to get the effect of adding one True\n",
    "        assert comb[1].sum() > comb[0].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the decay rates of each group -- this time in logscale\n",
    "fig = plt.figure(figsize=(dfig*2,dfig*1.5), constrained_layout=True)\n",
    "ax = fig.add_subplot(111)\n",
    "# nrows = 10\n",
    "# gs = fig.add_gridspec(ncols=1, nrows=nrows)\n",
    "# ax = fig.add_subplot(gs[:])\n",
    "# ax = fig.add_subplot(gs[1:nrows,:])\n",
    "ax = PrettyBox(data=deg_rates_log, fliersize=1, color=color_dict['grey'])\n",
    "ax.set_ylabel('decay rate log'r'$_{10}$'' (1 / min)')\n",
    "ngenes = [len(i) for i in deg_rates]\n",
    "labels = [f'{l}\\n[{n}]' for (l,n) in zip(group_df['tuple_label'], ngenes)]\n",
    "_ = ax.set_xticklabels(labels)\n",
    "# c = Connector(ax)\n",
    "# for i in ordered_pairs:\n",
    "#     c.add_connector(ax, i)\n",
    "pred_str = f'({\",\".join(predictors)})'\n",
    "ax.text(0, 1.06, f'{pred_str} 1 = present, 0 = not present\\n[num genes]', transform=ax.transAxes)\n",
    "plt.savefig('%s.%s' % (os.path.join(outdir, 'decay_groups_boxplot_log'), out_fmt), dpi = out_dpi)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mark the effect of having TF and me3 together, to put an asterix on the plot to indicate these\n",
    "TF_index = np.where(np.array(predictors) == 'TF')[0][0]\n",
    "me3_index = np.where(np.array(predictors) == 'me3')[0][0]\n",
    "CTS_index = np.where(np.array(predictors) == 'CTS')[0][0]\n",
    "for i,l in enumerate(group_arr):\n",
    "    sum = np.sum([l[TF_index], l[me3_index]])\n",
    "    if sum == 2 and np.sum(l) == 2:\n",
    "        double_comp_index = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The sign flip for the (1,0,0) vs. (0,0,0) in linear is quite confusing compared to the log case.\n",
    "# Should we be sticking with the log?\n",
    "# Should we be using the median instead?\n",
    "group1_mean_linear = df.query('TF==1&CTS==0&me3==0')['deg_rate_wins_1'].mean()\n",
    "group0_mean_linear = df.query('TF==0&CTS==0&me3==0')['deg_rate_wins_1'].mean()\n",
    "group1_med_linear = df.query('TF==1&CTS==0&me3==0')['deg_rate_wins_1'].median()\n",
    "group0_med_linear = df.query('TF==0&CTS==0&me3==0')['deg_rate_wins_1'].median()\n",
    "\n",
    "group1_mean_log = df.query('TF==1&CTS==0&me3==0')['log_deg_wins_1'].mean()\n",
    "group0_mean_log = df.query('TF==0&CTS==0&me3==0')['log_deg_wins_1'].mean()\n",
    "group1_med_log = df.query('TF==1&CTS==0&me3==0')['log_deg_wins_1'].median()\n",
    "group0_med_log = df.query('TF==0&CTS==0&me3==0')['log_deg_wins_1'].median()\n",
    "\n",
    "mean_linear_ratio = group1_mean_linear/group0_mean_linear\n",
    "med_linear_ratio = group1_med_linear/group0_med_linear\n",
    "\n",
    "# Convert log ratios back to linear for easy comparison\n",
    "mean_log_ratio = 10**(group1_mean_log - group0_mean_log)\n",
    "med_log_ratio = 10**(group1_med_log - group0_med_log)\n",
    "\n",
    "pd.DataFrame({'linear':{'mean_ratio':mean_linear_ratio, 'med_ratio':med_linear_ratio}, \n",
    "              'log':{'mean_ratio':mean_log_ratio, 'med_ratio':med_log_ratio}})\n",
    "# print('linear values:\\nmeans:\\ngroup0: %1.3f\\ngroup1: %1.3f\\nmedians:\\ngroup0: %1.3f\\ngroup1: %1.3f\\n' \n",
    "#        % (group0_mean_linear, group1_mean_linear, group0_med_linear, group1_med_linear))\n",
    "\n",
    "# print('log values:\\nmeans:\\ngroup0: %1.3f\\ngroup1: %1.3f\\nmedians:\\ngroup0: %1.3f\\ngroup1: %1.3f\\n' \n",
    "#        % (group0_mean_log, group1_mean_log, group0_med_log, group1_med_log))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the ratio of mean decay rates between groups\n",
    "# Keep track of mean and median and linear and log ratios between groups\n",
    "def ratio_array(deg_rates, passed_pairs, double_comp_index, CTS_index, log=False, agg='mean'):\n",
    "    '''Calculate ratios between groups, return array of shape (num groups, num comparisons)'''\n",
    "\n",
    "    ratios = []\n",
    "    n = []\n",
    "    # 0, 1, 2\n",
    "    for pos in sorted(list(passed_pairs.keys())):\n",
    "        pos_ratios = []\n",
    "        pos_genes = []\n",
    "        for pair in passed_pairs[pos]:\n",
    "            i, j = pair\n",
    "            # Effect of True compared to False is index 1/index 0\n",
    "            if log:\n",
    "                # Convert to log2 changes\n",
    "                if agg == 'mean':\n",
    "                    ratio = (deg_rates[j].mean() - deg_rates[i].mean())/math.log(2,10)\n",
    "                else:\n",
    "                    ratio = (np.median(deg_rates[j]) - np.median(deg_rates[i]))/math.log(2,10)\n",
    "            else:\n",
    "                if agg == 'mean':\n",
    "                    ratio = np.log2(deg_rates[j].mean()/deg_rates[i].mean())\n",
    "                else:\n",
    "                    ratio = np.log2(np.median(deg_rates[j])/np.median(deg_rates[i]))\n",
    "            pos_ratios.append(ratio)\n",
    "            pos_genes.append(f'{ngenes[j]} / {ngenes[i]}')\n",
    "            if (double_comp_index in [i, j]) and (pos != CTS_index):\n",
    "                pos_genes[-1] = '*' + pos_genes[-1]\n",
    "        ratios.append(pos_ratios)\n",
    "        n.append(pos_genes)\n",
    "    ngenes_a = np.array(n)\n",
    "    ratio_a = np.array(ratios)\n",
    "    return ratio_a, ngenes_a\n",
    "\n",
    "ratio_lin_mean, ngenes_a = ratio_array(deg_rates, passed_pairs, double_comp_index, CTS_index)\n",
    "ratio_lin_med, ngenes_a = ratio_array(deg_rates, passed_pairs, double_comp_index, CTS_index, agg='median')\n",
    "ratio_log_mean, ngenes_a = ratio_array(deg_rates_log, passed_pairs, double_comp_index, CTS_index, log=True)\n",
    "ratio_log_med, n_genes_a = ratio_array(deg_rates_log, passed_pairs, double_comp_index, CTS_index, log=True, agg='median')\n",
    "\n",
    "ratio_arrays = {'lin_mean':ratio_lin_mean, 'lin_med':ratio_lin_med, 'log_mean':ratio_log_mean, 'log_med':ratio_log_med}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean ratio for the linear data gives lower decay rates for the TFs, but median ratio is more simlar to the log case (~20% higher decay rate for group1 compared to group0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the ratio of decay rate means between groups\n",
    "def group_hm(ratio_a_log2, plotname, y_label):\n",
    "    '''Plot a heatmap showing the log2 changes between groups'''\n",
    "\n",
    "    # Get the range of the data and make symmetrical so that red=+ve and blue=-ve\n",
    "    max_val = abs(max(ratio_a_log2.min(), ratio_a_log2.max(), key=abs))\n",
    "    max_pos = (max_val//0.1)*0.1 + 0.1\n",
    "    max_neg = -max_pos\n",
    "    nrows = ratio_a_log2.shape[0]\n",
    "    # fig = plt.figure(figsize=(whole_page, dfig*1.5))\n",
    "    fig = plt.figure(figsize=(dfig*2, dfig*1.5))\n",
    "    gs = fig.add_gridspec(ncols=20, nrows=nrows, hspace=0.5)\n",
    "    # cbar_ax = fig.add_subplot(gs[:,-1])\n",
    "    cbar_ax = fig.add_subplot(gs[:,-2])\n",
    "    for i in range(nrows):\n",
    "        # ax = fig.add_subplot(gs[i,:-1])\n",
    "        ax = fig.add_subplot(gs[i,:-2])\n",
    "        if i == 0:\n",
    "            # ax = sns.heatmap(ratio_a[i].reshape(1,-1), vmin=-0.5, vmax=0.5, cmap='seismic', cbar_ax=cbar_ax, cbar_kws={'label':'effect of adding factor (log'r'$_{10}$'')'})\n",
    "            # ax = sns.heatmap(ratio_a[i].reshape(1,-1), vmin=max_neg, vmax=max_pos, cmap='seismic', cbar_ax=cbar_ax, cbar_kws={'label':'+factor / -factor (log'r'$_{10}$'' mean / mean)'},\n",
    "            ax = sns.heatmap(ratio_a_log2[i].reshape(1,-1), vmin=max_neg, vmax=max_pos, cmap='seismic',\n",
    "                             cbar_ax=cbar_ax, cbar_kws={'label':y_label},\n",
    "                             annot=ngenes_a[i].reshape(1,-1), fmt='')\n",
    "        else:\n",
    "            ax = sns.heatmap(ratio_a_log2[i].reshape(1,-1), vmin=max_neg, vmax=max_pos, cmap='seismic', cbar=False, annot=ngenes_a[i].reshape(1,-1), fmt='')\n",
    "        ax.set_yticklabels([predictors[i]])\n",
    "        # We should actually put thi the other way around to make it match with the +factor/-factor\n",
    "        label_a = np.array(group_df['tuple_label'])[passed_pairs[i]]\n",
    "        col1 = label_a[:, 0].reshape(-1, 1)\n",
    "        col2 = label_a[:, 1].reshape(-1, 1)\n",
    "        label_a2 = np.hstack([col2, col1])\n",
    "        xlabels = np.apply_along_axis(lambda x: ' / '.join(x), 1, label_a2)\n",
    "        ax.set_xticklabels(xlabels, fontsize=6)\n",
    "    fig.text(0.007, 0.5, 'feature varying between groups', rotation=90, va='center', ha='left')\n",
    "    fig.text(0.5, 0.9, 'n genes / n genes', ha='center', va='bottom')\n",
    "    # fig.text(0.5, 0.01, 'group ID (0 = false, 1 = true for: TF, me3, CTS)', ha='center', va='bottom')\n",
    "    plt.savefig('%s.%s' % (os.path.join(outdir, plotname), out_fmt), dpi = out_dpi)\n",
    "\n",
    "# ratio_arrays = {'lin_mean':ratio_lin_mean, 'lin_med':ratio_lin_med, 'log_mean':ratio_log_mean, 'log_med':ratio_log_med}\n",
    "# group_hm(ratio_arrays['lin_mean'], 'group_hm_lin_mean', y_label='ratio of group means (log'r'$_{2}$'' mean / mean)')\n",
    "# group_hm(ratio_arrays['lin_med'], 'group_hm_lin_med', y_label='ratio of group means (log'r'$_{2}$'' median / median)')\n",
    "group_hm(ratio_arrays['log_mean'], 'group_hm_log_mean', y_label='ratio of group means (log'r'$_{2}$'' mean / mean)')\n",
    "# group_hm(ratio_arrays['log_med'], 'group_hm_log_med', y_label='ratio of group means (log'r'$_{2}$'' median / median)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part II: Bootstrapping to get more accurate coefficients with the given group sizes\n",
    "1) Find size of smallest group (N)\n",
    "2) Choose random seed\n",
    "3) Sample the N from each of the groups with replacement\n",
    "4) Run 10,000 times (bootstraps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_OLS(df, target_column, predictors, interactions=False):\n",
    "    '''\n",
    "    Run linear regression on the data given a target column and predictors.\n",
    "    Use statsmodels.ols and pass in a dataframe with either the actual predictor names\n",
    "    or a betas, which need to be specified via another mapping df.\n",
    "    beta_df = df with integer labelled columns corresponding to the predictors (i.e. [0,1,2]),\n",
    "    1/0 in each row and a column called 'beta_label'.\n",
    "    '''\n",
    "    X = df[predictors].values\n",
    "    y = df[target_column].values\n",
    "    n_comb = 2**len(predictors)\n",
    "    # Betas should map to the same combinations in group_df since these were extracted with PolynomialFeatures()\n",
    "    betas = ['$\\\\beta_{%s}$' % i for i in range(n_comb)]\n",
    "    \n",
    "    if interactions:\n",
    "        poly = PolynomialFeatures(interaction_only=True, degree=len(predictors))\n",
    "        # When using PolynomialFeatures, it already adds a constant.\n",
    "        X_tr = poly.fit_transform(X)\n",
    "        Xt = pd.DataFrame(X_tr, columns=betas)\n",
    "        mod = sm.OLS(y, Xt)\n",
    "        res = mod.fit()\n",
    "        res.summary()\n",
    "    else:\n",
    "        X1 = sm.add_constant(X.astype(int))\n",
    "        X1 = pd.DataFrame(X1, columns=betas[0:len(predictors)+1])\n",
    "        mod = sm.OLS(y, X1)\n",
    "        res = mod.fit()\n",
    "        res.summary()\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the linear regression coefficients and pvalues via bootstrapping\n",
    "def bootstrap_sample(rates, group_arr, samp_n=30, seed_num=0, shuffle=False):\n",
    "    '''\n",
    "    Select a random sample from each of the groups.\n",
    "    rates = a list of arrays, ordered by group\n",
    "    group_arr = an array of shape (num_groups, num_predictors) with 0/1 to show membership\n",
    "    samp_n = number of samples to take from each group\n",
    "    returns group_samp_arr = array of shape (samp_n*len(rates), num_predictors + 1)\n",
    "    '''\n",
    "    group_rates = []\n",
    "    np.random.seed(seed_num)\n",
    "    predictors_n = group_arr.shape[1]\n",
    "    for j in range(len(rates)):\n",
    "        a = np.random.randint(0, len(rates[j]), size=samp_n)\n",
    "        samp = np.take(rates[j], a).reshape(-1,1)\n",
    "        # Add in predictor columns\n",
    "        arr = np.broadcast_to(group_arr[j], (samp_n, predictors_n))\n",
    "        group_rates.append(np.hstack([samp, arr]))\n",
    "    group_samp_arr = np.vstack(group_rates)\n",
    "    if shuffle:\n",
    "        np.random.shuffle(group_samp_arr)\n",
    "    return group_samp_arr\n",
    "\n",
    "def run_bootstrap(deg_rates, group_arr, samp_n=30, bootstrap_n=100):\n",
    "    '''Run all iterations of bootstrap and model building'''\n",
    "    res_d = {k:{'coeff':[], 'pvalues':[]} for k in ['minus_int', 'plus_int']}\n",
    "    for i in range(bootstrap_n):\n",
    "        # random seed will be a multiple of 997 (i+1, so it starts with 997)\n",
    "        # random seed the same for all groups in the same bootstrap iteration\n",
    "        seed_num = 104729*(i+1) + 997*i\n",
    "        group_samp_arr = bootstrap_sample(deg_rates, group_arr, samp_n=samp_n, seed_num=seed_num, shuffle=False)\n",
    "        bdf = pd.DataFrame(group_samp_arr, columns=[target_column] + predictors)\n",
    "        res = run_OLS(bdf, target_column, predictors, interactions=False)\n",
    "        res_int = run_OLS(bdf, target_column, predictors, interactions=True)\n",
    "        res_d['minus_int']['coeff'].append(res.params)\n",
    "        res_d['minus_int']['pvalues'].append(res.pvalues)\n",
    "        res_d['plus_int']['coeff'].append(res_int.params)\n",
    "        res_d['plus_int']['pvalues'].append(res_int.pvalues)\n",
    "\n",
    "    res_d['minus_int']['coeff'] = pd.concat(res_d['minus_int']['coeff'], axis=1).transpose()\n",
    "    res_d['minus_int']['pvalues'] = pd.concat(res_d['minus_int']['pvalues'], axis=1).transpose()\n",
    "    res_d['plus_int']['coeff'] = pd.concat(res_d['plus_int']['coeff'], axis=1).transpose()\n",
    "    res_d['plus_int']['pvalues'] = pd.concat(res_d['plus_int']['pvalues'], axis=1).transpose()\n",
    "    return res_d\n",
    "\n",
    "samp_n = min(ngenes)\n",
    "print('min gene num', samp_n)\n",
    "# bootstrap_n = 100 #CHANGE TO 10000 FOR THE FINAL VERSION\n",
    "bootstrap_n = 10000 #CHANGE TO 10000 FOR THE FINAL VERSION\n",
    "# res_bootstrap_lin = run_bootstrap(deg_rates, group_arr, samp_n=samp_n, bootstrap_n=bootstrap_n)\n",
    "if run_bootstrap_fxn:\n",
    "    res_bootstrap_log = run_bootstrap(deg_rates_log, group_arr, samp_n=samp_n, bootstrap_n=bootstrap_n)\n",
    "    with open(os.path.join(outdir, 'bootstrap_res.pickle'), 'wb') as f:\n",
    "        pickle.dump(res_bootstrap_log, f)\n",
    "else:\n",
    "    with open(os.path.join(outdir, 'bootstrap_res.pickle'), 'rb') as f:\n",
    "        res_bootstrap_log = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As a comparison, plot the coefficents obtained from all data\n",
    "# Get predictor values for each group and merge with the data\n",
    "def lr_all_data(deg_rates, group_arr):\n",
    "    '''Run linear regression on all data'''\n",
    "    res_d = {k:{'coeff':[], 'pvalues':[]} for k in ['minus_int', 'plus_int']}\n",
    "\n",
    "    id_vals = []\n",
    "    for j in range(len(group_arr)):\n",
    "        arr = np.broadcast_to(group_arr[j], (len(deg_rates[j]), len(predictors)))\n",
    "        id_vals.append(arr)\n",
    "    id_cols = np.vstack(id_vals)\n",
    "    vals = np.hstack(deg_rates).reshape(-1,1)\n",
    "    big_df = pd.DataFrame(np.hstack([vals, id_cols]), columns=[target_column] + predictors)\n",
    "    res = run_OLS(big_df, target_column, predictors, interactions=False)\n",
    "    res_int = run_OLS(big_df, target_column, predictors, interactions=True)\n",
    "    res_d['minus_int']['coeff'] = res.params\n",
    "    res_d['minus_int']['pvalues'] = res.pvalues\n",
    "    res_d['plus_int']['coeff'] = res_int.params\n",
    "    res_d['plus_int']['pvalues'] = res_int.pvalues\n",
    "    return res_d\n",
    "\n",
    "res_all_lin = lr_all_data(deg_rates, group_arr)\n",
    "res_all_log = lr_all_data(deg_rates_log, group_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this version plot the intercept on a different axis to allow different scales\n",
    "# Plot the coefficents and p-values from bootstrapping of both log and linear data\n",
    "# For this version, plot the intercept on a different axis to allow different scales \n",
    "# and don't do the split axis\n",
    "def inf_vals(a, ax):\n",
    "    '''Return data axis coords where array is inf'''\n",
    "    idx = [i for i,j in enumerate(a) if not np.isfinite(j)]\n",
    "    x2 = []\n",
    "    for x in idx:\n",
    "        x1, y1 = data_to_axis(ax, (x, 1))\n",
    "        x2.append(x1)\n",
    "    return x2\n",
    "\n",
    "def data_to_axis(ax, point):\n",
    "    '''transform data to axis coords. point should be (x,y)'''\n",
    "    axis_to_data = ax.transAxes + ax.transData.inverted()\n",
    "    data_to_axis = axis_to_data.inverted()\n",
    "    x1, y1 = data_to_axis.transform(point)\n",
    "    return x1, y1\n",
    "\n",
    "def write_pvals(pvals, axes):\n",
    "    '''Write the pvalues onto the axes. axes = [left_ax, right_ax]'''\n",
    "    pval_co = -math.log(0.05, 10)\n",
    "    for i,s in enumerate(pvals):\n",
    "        if s < pval_co:\n",
    "            s2 = 'ns'\n",
    "        else:\n",
    "            s2 = '%1.0f' % s\n",
    "        if i == 0:\n",
    "            point = (i, 1)\n",
    "            x, y = data_to_axis(axes[0], point)\n",
    "            axes[0].text(x, 1, s2, transform=axes[0].transAxes, color='b', ha='center')\n",
    "        else:\n",
    "            point = (i - 1, 1)\n",
    "            x, y = data_to_axis(axes[1], point)\n",
    "            axes[1].text(x, 1, s2, transform=axes[1].transAxes, color='b', ha='center')\n",
    "\n",
    "def plot_regression_results(res_bootstrap, res_all, toplot='coeff', y_label='', **kwargs):\n",
    "    # fig = plt.figure(figsize=(dfig*2, dfig*1.5), constrained_layout=True)\n",
    "    fig = plt.figure(figsize=(dfig*2, dfig*1.5))\n",
    "    # Need to manually set the spacing here in order to get the boxes to be placed at the same place top and bottom\n",
    "    lstart = 0.13\n",
    "    hstart = 0.09\n",
    "    height = 0.33\n",
    "    hstart2 = hstart+height+0.1755\n",
    "    plots_width = 0.76\n",
    "    single_plot = plots_width/8\n",
    "    wspace=0.1\n",
    "\n",
    "    ax1_bottom = fig.add_axes([lstart, hstart, single_plot, height])\n",
    "    ax2_bottom = fig.add_axes([lstart+single_plot+wspace, hstart, single_plot*7, height])\n",
    "    ax1_top = fig.add_axes([lstart, hstart2, single_plot, height])\n",
    "    ax2_top = fig.add_axes([lstart+single_plot+wspace, hstart2, single_plot*3, height])\n",
    "    if toplot == 'pvalues':\n",
    "        bdf_minus = -res_bootstrap['minus_int'][toplot].apply(np.log10)\n",
    "        bdf_plus = -res_bootstrap['plus_int'][toplot].apply(np.log10)\n",
    "        all_minus = -res_all['minus_int'][toplot].apply(np.log10)\n",
    "        all_plus = -res_all['plus_int'][toplot].apply(np.log10)\n",
    "    else:\n",
    "        bdf_minus = res_bootstrap['minus_int'][toplot]\n",
    "        bdf_plus = res_bootstrap['plus_int'][toplot]\n",
    "        all_minus = res_all['minus_int'][toplot]\n",
    "        all_plus = res_all['plus_int'][toplot]\n",
    "\n",
    "    ax1_top = PrettyBox(data=bdf_minus[[bdf_minus.columns[0]]], fliersize=1, color=color_dict['grey'], ax=ax1_top)\n",
    "    ax2_top = PrettyBox(data=bdf_minus[bdf_minus.columns[1:]], fliersize=1, color=color_dict['grey'], ax=ax2_top)\n",
    "    ax1_bottom = PrettyBox(data=bdf_plus[[bdf_plus.columns[0]]], fliersize=1, color=color_dict['grey'], ax=ax1_bottom)\n",
    "    ax2_bottom = PrettyBox(data=bdf_plus[bdf_plus.columns[1:]], fliersize=1, color=color_dict['grey'], ax=ax2_bottom)\n",
    "\n",
    "    # Plot the non-bootstrapped coefficients\n",
    "    if toplot == 'coeff':\n",
    "        coeff_vals_minus = all_minus.values\n",
    "        x_inf1_minus = inf_vals(coeff_vals_minus, ax1_top)\n",
    "        x_inf2_minus = inf_vals(coeff_vals_minus, ax2_top)\n",
    "        ax1_top.scatter(np.arange(0, 1), coeff_vals_minus[0], color='b', zorder=10, marker='D', s=6, label='values from all data')\n",
    "        ax1_top.scatter(x_inf1_minus, [0.95]*len(x_inf1_minus), marker='^', color='b', transform=ax1_top.transAxes)\n",
    "        ax2_top.scatter(np.arange(0, len(coeff_vals_minus)-1), coeff_vals_minus[1:], color='b', zorder=10, marker='D', s=6, label='values from all data')\n",
    "        ax1_top.scatter(x_inf2_minus, [0.95]*len(x_inf1_minus), marker='^', color='b', transform=ax2_top.transAxes)\n",
    "\n",
    "        coeff_vals_plus = all_plus.values\n",
    "        x_inf1_plus = inf_vals(coeff_vals_plus, ax1_bottom)\n",
    "        x_inf2_plus = inf_vals(coeff_vals_plus, ax2_bottom)\n",
    "        ax1_bottom.scatter(np.arange(0, 1), coeff_vals_plus[0], color='b', zorder=10, marker='D', s=6, label='values from all data')\n",
    "        ax1_bottom.scatter(x_inf1_plus, [0.95]*len(x_inf1_plus), marker='^', color='b', transform=ax1_bottom.transAxes)\n",
    "        ax2_bottom.scatter(np.arange(0, len(coeff_vals_plus)-1), coeff_vals_plus[1:], color='b', zorder=10, marker='D', s=6, label='values from all data')\n",
    "        ax1_bottom.scatter(x_inf2_plus, [0.95]*len(x_inf1_plus), marker='^', color='b', transform=ax2_bottom.transAxes)\n",
    "\n",
    "    if toplot == 'pvalues':\n",
    "        pvals_minus = all_minus.values\n",
    "        pvals_plus = all_plus.values\n",
    "        write_pvals(pvals_minus, [ax1_top, ax2_top])\n",
    "        write_pvals(pvals_plus, [ax1_bottom, ax2_bottom])\n",
    "\n",
    "    # Put the model label in the middle with respect to the bottom axis\n",
    "    x1, y1 = data_to_axis(ax2_top, (6.5, 5))\n",
    "    x2, y2 = data_to_axis(ax2_bottom, (6.5, 5))\n",
    "    # ax2_top.text(x1, 1.07, 'no interactions', va='bottom', ha='right', transform=ax2_top.transAxes)\n",
    "    # ax2_bottom.text(x2, 1.07, '+ interactions', va='bottom', ha='right', transform=ax2_bottom.transAxes)\n",
    "    ax1_top.text(0, 1.08, 'model - interactions', va='bottom', ha='left', transform=ax1_top.transAxes)\n",
    "    ax1_bottom.text(0, 1.08, 'model + interactions', va='bottom', ha='left', transform=ax1_bottom.transAxes)\n",
    "    # ax2_top.text(1, 0.5, 'no interactions', rotation=-90, va='center', transform=ax2_top.transAxes)\n",
    "    # ax2_bottom.text(1, 0.5, '+ interactions', rotation=-90, va='center', transform=ax2_bottom.transAxes)\n",
    "\n",
    "    axes = [ax1_top, ax2_top, ax1_bottom, ax2_bottom]\n",
    "    # Limit the grey lines to the non-intercept axes, otherwise it takes too much room\n",
    "    if toplot == 'pvalues':\n",
    "        ax2_top.axhline(y=-math.log(0.05, 10), linestyle='--', color=color_dict['grey'], zorder=0)\n",
    "        ax2_bottom.axhline(y=-math.log(0.05, 10), linestyle='--', color=color_dict['grey'], zorder=0)\n",
    "    else:\n",
    "        ax2_top.axhline(y=0, linestyle='--', color=color_dict['grey'], zorder=0)\n",
    "        ax2_bottom.axhline(y=0, linestyle='--', color=color_dict['grey'], zorder=0)\n",
    "        ax1_top.yaxis.set_major_locator(plticker.MultipleLocator(base=0.1))\n",
    "        ax2_top.yaxis.set_major_locator(plticker.MultipleLocator(base=0.2))\n",
    "        ax1_bottom.yaxis.set_major_locator(plticker.MultipleLocator(base=0.2))\n",
    "        ax2_bottom.yaxis.set_major_locator(plticker.MultipleLocator(base=0.4))\n",
    "\n",
    "    return [ax1_top, ax2_top, ax1_bottom, ax2_bottom], fig\n",
    "\n",
    "# Plot p-values\n",
    "# If split axes don't help much to visualize the p-values, perhaps better to just write them above the plot\n",
    "axes, fig = plot_regression_results(res_bootstrap_log, res_all_log, toplot='pvalues', y_label='p-values from bootstraps (-log'r'$_{10}$)')\n",
    "y_label='p-values from bootstraps (-log'r'$_{10}$)'\n",
    "big_ax = fig.add_subplot(111, frameon=False)\n",
    "# hide tick and tick label of the big axis\n",
    "plt.tick_params(labelcolor='none', which='both', top=False, bottom=False, left=False, right=False)\n",
    "big_ax.set_ylabel(y_label, labelpad=5)\n",
    "plt.savefig('%s.%s' % (os.path.join(outdir, 'bootstrap_pvals_log'), out_fmt), dpi = out_dpi)\n",
    "\n",
    "# Plot coefficients\n",
    "axes, fig = plot_regression_results(res_bootstrap_log, res_all_log, y_label=f'bootstrap coefficients (N = {bootstrap_n})')\n",
    "y_label=f'bootstrap coefficients (N = {bootstrap_n})'\n",
    "axes[1].legend(loc='lower left', bbox_to_anchor=(1, 0))\n",
    "big_ax = fig.add_subplot(111, frameon=False)\n",
    "# hide tick and tick label of the big axis\n",
    "plt.tick_params(labelcolor='none', which='both', top=False, bottom=False, left=False, right=False)\n",
    "big_ax.set_ylabel(y_label, labelpad=5)\n",
    "plt.savefig('%s.%s' % (os.path.join(outdir, 'bootstrap_coeffs_log'), out_fmt), dpi = out_dpi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this version plot the intercept on a different axis to allow different scales\n",
    "# Plot the coefficents and p-values from bootstrapping of both log and linear data\n",
    "# For this version, plot the intercept on a different axis to allow different scales \n",
    "# and don't do the split axis\n",
    "def inf_vals(a, ax):\n",
    "    '''Return data axis coords where array is inf'''\n",
    "    idx = [i for i,j in enumerate(a) if not np.isfinite(j)]\n",
    "    x2 = []\n",
    "    for x in idx:\n",
    "        x1, y1 = data_to_axis(ax, (x, 1))\n",
    "        x2.append(x1)\n",
    "    return x2\n",
    "\n",
    "def data_to_axis(ax, point):\n",
    "    '''transform data to axis coords. point should be (x,y)'''\n",
    "    axis_to_data = ax.transAxes + ax.transData.inverted()\n",
    "    data_to_axis = axis_to_data.inverted()\n",
    "    x1, y1 = data_to_axis.transform(point)\n",
    "    return x1, y1\n",
    "\n",
    "def write_pvals(pvals, axes):\n",
    "    '''Write the pvalues onto the axes. axes = [left_ax, right_ax]'''\n",
    "    pval_co = -math.log(0.05, 10)\n",
    "    for i,s in enumerate(pvals):\n",
    "        if s < pval_co:\n",
    "            s2 = 'ns'\n",
    "        else:\n",
    "            s2 = '%1.0f' % s\n",
    "        if i == 0:\n",
    "            point = (i, 1)\n",
    "            x, y = data_to_axis(axes[0], point)\n",
    "            axes[0].text(x, 1, s2, transform=axes[0].transAxes, color='b', ha='center')\n",
    "        else:\n",
    "            point = (i - 1, 1)\n",
    "            x, y = data_to_axis(axes[1], point)\n",
    "            axes[1].text(x, 1, s2, transform=axes[1].transAxes, color='b', ha='center')\n",
    "\n",
    "def plot_regression_results(res_bootstrap, res_all, toplot='coeff', y_label='', **kwargs):\n",
    "    # fig = plt.figure(figsize=(dfig*2, dfig*1.5), constrained_layout=True)\n",
    "    fig = plt.figure(figsize=(dfig*2, dfig*1.5))\n",
    "    # Need to manually set the spacing here in order to get the boxes to be placed at the same place top and bottom\n",
    "    lstart = 0.13\n",
    "    hstart = 0.09\n",
    "    height = 0.35\n",
    "    hstart2 = hstart+height+0.14\n",
    "    plots_width = 0.76\n",
    "    single_plot = plots_width/8\n",
    "    wspace=0.1\n",
    "\n",
    "    ax1_bottom = fig.add_axes([lstart, hstart, single_plot, height])\n",
    "    ax2_bottom = fig.add_axes([lstart+single_plot+wspace, hstart, single_plot*7, height])\n",
    "    ax1_top = fig.add_axes([lstart, hstart2, single_plot, height])\n",
    "    ax2_top = fig.add_axes([lstart+single_plot+wspace, hstart2, single_plot*3, height])\n",
    "    if toplot == 'pvalues':\n",
    "        bdf_minus = -res_bootstrap['minus_int'][toplot].apply(np.log10)\n",
    "        bdf_plus = -res_bootstrap['plus_int'][toplot].apply(np.log10)\n",
    "        all_minus = -res_all['minus_int'][toplot].apply(np.log10)\n",
    "        all_plus = -res_all['plus_int'][toplot].apply(np.log10)\n",
    "    else:\n",
    "        bdf_minus = res_bootstrap['minus_int'][toplot]\n",
    "        bdf_plus = res_bootstrap['plus_int'][toplot]\n",
    "        all_minus = res_all['minus_int'][toplot]\n",
    "        all_plus = res_all['plus_int'][toplot]\n",
    "\n",
    "    ax1_top = PrettyBox(data=bdf_minus[[bdf_minus.columns[0]]], fliersize=1, color=color_dict['grey'], ax=ax1_top)\n",
    "    ax2_top = PrettyBox(data=bdf_minus[bdf_minus.columns[1:]], fliersize=1, color=color_dict['grey'], ax=ax2_top)\n",
    "    ax1_bottom = PrettyBox(data=bdf_plus[[bdf_plus.columns[0]]], fliersize=1, color=color_dict['grey'], ax=ax1_bottom)\n",
    "    ax2_bottom = PrettyBox(data=bdf_plus[bdf_plus.columns[1:]], fliersize=1, color=color_dict['grey'], ax=ax2_bottom)\n",
    "\n",
    "    # Plot the non-bootstrapped coefficients\n",
    "    if toplot == 'coeff':\n",
    "        coeff_vals_minus = all_minus.values\n",
    "        x_inf1_minus = inf_vals(coeff_vals_minus, ax1_top)\n",
    "        x_inf2_minus = inf_vals(coeff_vals_minus, ax2_top)\n",
    "        ax1_top.scatter(np.arange(0, 1), coeff_vals_minus[0], color='b', zorder=10, marker='D', s=6, label='values from all data')\n",
    "        ax1_top.scatter(x_inf1_minus, [0.95]*len(x_inf1_minus), marker='^', color='b', transform=ax1_top.transAxes)\n",
    "        ax2_top.scatter(np.arange(0, len(coeff_vals_minus)-1), coeff_vals_minus[1:], color='b', zorder=10, marker='D', s=6, label='values from all data')\n",
    "        ax1_top.scatter(x_inf2_minus, [0.95]*len(x_inf1_minus), marker='^', color='b', transform=ax2_top.transAxes)\n",
    "\n",
    "        coeff_vals_plus = all_plus.values\n",
    "        x_inf1_plus = inf_vals(coeff_vals_plus, ax1_bottom)\n",
    "        x_inf2_plus = inf_vals(coeff_vals_plus, ax2_bottom)\n",
    "        ax1_bottom.scatter(np.arange(0, 1), coeff_vals_plus[0], color='b', zorder=10, marker='D', s=6, label='values from all data')\n",
    "        ax1_bottom.scatter(x_inf1_plus, [0.95]*len(x_inf1_plus), marker='^', color='b', transform=ax1_bottom.transAxes)\n",
    "        ax2_bottom.scatter(np.arange(0, len(coeff_vals_plus)-1), coeff_vals_plus[1:], color='b', zorder=10, marker='D', s=6, label='values from all data')\n",
    "        ax1_bottom.scatter(x_inf2_plus, [0.95]*len(x_inf1_plus), marker='^', color='b', transform=ax2_bottom.transAxes)\n",
    "\n",
    "    if toplot == 'pvalues':\n",
    "        pvals_minus = all_minus.values\n",
    "        pvals_plus = all_plus.values\n",
    "        write_pvals(pvals_minus, [ax1_top, ax2_top])\n",
    "        write_pvals(pvals_plus, [ax1_bottom, ax2_bottom])\n",
    "\n",
    "    # Put the model label in the middle with respect to the bottom axis\n",
    "    x1, y1 = data_to_axis(ax2_top, (6.5, 5))\n",
    "    x2, y2 = data_to_axis(ax2_bottom, (6.5, 5))\n",
    "    ax2_top.text(x1, 1.07, 'no interactions', va='bottom', ha='right', transform=ax2_top.transAxes)\n",
    "    ax2_bottom.text(x2, 1.07, '+ interactions', va='bottom', ha='right', transform=ax2_bottom.transAxes)\n",
    "    axes = [ax1_top, ax2_top, ax1_bottom, ax2_bottom]\n",
    "    # Limit the grey lines to the non-intercept axes, otherwise it takes too much room\n",
    "    if toplot == 'pvalues':\n",
    "        ax2_top.axhline(y=-math.log(0.05, 10), linestyle='--', color=color_dict['grey'], zorder=0)\n",
    "        ax2_bottom.axhline(y=-math.log(0.05, 10), linestyle='--', color=color_dict['grey'], zorder=0)\n",
    "    else:\n",
    "        ax2_top.axhline(y=0, linestyle='--', color=color_dict['grey'], zorder=0)\n",
    "        ax2_bottom.axhline(y=0, linestyle='--', color=color_dict['grey'], zorder=0)\n",
    "        ax1_top.yaxis.set_major_locator(plticker.MultipleLocator(base=0.1))\n",
    "        ax2_top.yaxis.set_major_locator(plticker.MultipleLocator(base=0.2))\n",
    "        ax1_bottom.yaxis.set_major_locator(plticker.MultipleLocator(base=0.2))\n",
    "        ax2_bottom.yaxis.set_major_locator(plticker.MultipleLocator(base=0.4))\n",
    "\n",
    "    return [ax1_top, ax2_top, ax1_bottom, ax2_bottom], fig\n",
    "\n",
    "# Plot p-values\n",
    "# If split axes don't help much to visualize the p-values, perhaps better to just write them above the plot\n",
    "axes, fig = plot_regression_results(res_bootstrap_log, res_all_log, toplot='pvalues', y_label='p-values from bootstraps (-log'r'$_{10}$)')\n",
    "y_label='p-values from bootstraps (-log'r'$_{10}$)'\n",
    "big_ax = fig.add_subplot(111, frameon=False)\n",
    "# hide tick and tick label of the big axis\n",
    "plt.tick_params(labelcolor='none', which='both', top=False, bottom=False, left=False, right=False)\n",
    "big_ax.set_ylabel(y_label, labelpad=5)\n",
    "plt.savefig('%s.%s' % (os.path.join(outdir, 'bootstrap_pvals_log'), out_fmt), dpi = out_dpi)\n",
    "\n",
    "# Plot coefficients\n",
    "axes, fig = plot_regression_results(res_bootstrap_log, res_all_log, y_label=f'bootstrap coefficients (N = {bootstrap_n})')\n",
    "y_label=f'bootstrap coefficients (N = {bootstrap_n})'\n",
    "axes[1].legend(loc='lower left', bbox_to_anchor=(0, 0.94))\n",
    "big_ax = fig.add_subplot(111, frameon=False)\n",
    "# hide tick and tick label of the big axis\n",
    "plt.tick_params(labelcolor='none', which='both', top=False, bottom=False, left=False, right=False)\n",
    "big_ax.set_ylabel(y_label, labelpad=5)\n",
    "plt.savefig('%s.%s' % (os.path.join(outdir, 'bootstrap_coeffs_log'), out_fmt), dpi = out_dpi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the bootstrap function with different seeds and +/- shuffle\n",
    "def prime_seed(i):\n",
    "    seed = 104729*(i+1) + 997*i\n",
    "    return seed\n",
    "\n",
    "def zero_seed(i):\n",
    "    '''Just returns 0. Doesn't really make sense for multiple iterations as always the same.'''\n",
    "    return 0\n",
    "\n",
    "def test_bootstrap(deg_rates, group_arr, samp_n=samp_n, seed_fxn=prime_seed, bootstrap_n=100, shuffle=False, interactions=False, \n",
    "                   target_column=target_column, predictors=predictors):\n",
    "\n",
    "    res_d = {'pvalues':[], 'coeff':[]}\n",
    "    for i in range(bootstrap_n):\n",
    "        seed_num = seed_fxn(i)\n",
    "        group_samp_arr = bootstrap_sample(deg_rates, group_arr, samp_n=samp_n, seed_num=seed_num, shuffle=shuffle)\n",
    "        bdf = pd.DataFrame(group_samp_arr, columns=[target_column] + predictors)\n",
    "        res = run_OLS(bdf, target_column, predictors, interactions=interactions)\n",
    "        res_d['pvalues'].append(res.pvalues)\n",
    "        res_d['coeff'].append(res.params)\n",
    "    \n",
    "    final_res_d = {}\n",
    "    final_res_d['coeff'] = pd.concat(res_d['coeff'], axis=1).transpose()\n",
    "    final_res_d['pvalues'] = pd.concat(res_d['pvalues'], axis=1).transpose()\n",
    "    return final_res_d\n",
    "\n",
    "res_noshuff = test_bootstrap(deg_rates, group_arr, samp_n=samp_n, seed_fxn=prime_seed, shuffle=False, target_column=target_column, predictors=predictors)\n",
    "res_shuff = test_bootstrap(deg_rates, group_arr, samp_n=samp_n, seed_fxn=prime_seed, shuffle=True, target_column=target_column, predictors=predictors)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('pretty')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "bdb49103a4ed208a05ea4530afbe53462c06fafea10c7833b005d674746fdb08"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
