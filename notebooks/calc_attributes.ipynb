{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "announced-healing",
   "metadata": {},
   "source": [
    "#### calc attributes\n",
    "- Look at physical attributes of the genes\n",
    "- transcript length, CDS, intron length, UTR lengths\n",
    "- GC content\n",
    "- codon optimality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "failing-equality",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import os\n",
    "import gffutils\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import scipy.stats as stats\n",
    "from Bio import SeqIO\n",
    "from Bio.Seq import Seq\n",
    "import pickle\n",
    "from pyfaidx import Fasta\n",
    "\n",
    "sys.path.append('../scripts')\n",
    "from plot_helpers import *\n",
    "\n",
    "db = gffutils.FeatureDB(gffutils_db)\n",
    "\n",
    "outdir = '../Figures/gene_attributes/'\n",
    "os.makedirs(outdir, exist_ok=True)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stone-dealing",
   "metadata": {},
   "outputs": [],
   "source": [
    "seqs_dir = '/Users/mk/Desktop/Davislab_old/3.4_NMJ_4Tu_4sU/3.4e_pipeline_dev/nmj_figures/resources/region_fastas'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "clean-opening",
   "metadata": {},
   "source": [
    "#### Part I: Examine the UTR "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dying-colony",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get UTR lengths of ASR genes\n",
    "bg_genes = db.features_of_type('gene')\n",
    "#background set should be all genes that passed the filter:\n",
    "tutr_d = defaultdict(list)\n",
    "futr_d = defaultdict(list)\n",
    "txt_d = defaultdict(list)\n",
    "cds_d = defaultdict(list)\n",
    "p=0\n",
    "for i in bg_genes:\n",
    "    txts = db.children(i.id, featuretype='transcript')\n",
    "    for t in txts:\n",
    "        tlen = db.children_bp(t, child_featuretype='three_prime_utr')\n",
    "        flen = db.children_bp(t, child_featuretype='five_prime_utr')\n",
    "        txtlen = db.children_bp(t, child_featuretype='exon')\n",
    "        cdslen = db.children_bp(t, child_featuretype='CDS')\n",
    "        tutr_d[i.id].append((tlen, t.id))\n",
    "        futr_d[i.id].append((flen, t.id))\n",
    "        txt_d[i.id].append((txtlen, t.id))\n",
    "        cds_d[i.id].append((cdslen, t.id))\n",
    "    p+=1\n",
    "    #if p>0:\n",
    "    #    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enabling-action",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finds the transcript with the longest length\n",
    "max_tutr = {k:max(v) for (k,v) in tutr_d.items()}\n",
    "max_futr = {k:max(v) for (k,v) in futr_d.items()}\n",
    "max_txt = {k:max(v) for (k,v) in txt_d.items()}\n",
    "max_cds = {k:max(v) for (k,v) in cds_d.items()}\n",
    "\n",
    "# Finds the longest length\n",
    "max_tutr_len = {k:max(v)[0] for (k,v) in tutr_d.items()}\n",
    "max_futr_len = {k:max(v)[0] for (k,v) in futr_d.items()}\n",
    "max_txt_len = {k:max(v)[0] for (k,v) in txt_d.items()}\n",
    "max_cds_len = {k:max(v)[0] for (k,v) in cds_d.items()}\n",
    "\n",
    "# Finds the ID corresponding to the longest length\n",
    "max_tutr_id = {k:max(v)[1] for (k,v) in tutr_d.items()}\n",
    "max_futr_id = {k:max(v)[1] for (k,v) in futr_d.items()}\n",
    "max_txt_id = {k:max(v)[1] for (k,v) in txt_d.items()}\n",
    "max_txt_cds = {k:max(v)[1] for (k,v) in cds_d.items()}\n",
    "\n",
    "# Make a dataframe with all the lengths\n",
    "df = pd.DataFrame.from_dict(max_tutr_len, orient='index', columns = ['tutr_len'])\n",
    "df['futr_len'] = df.index.map(max_futr_len)\n",
    "df['cds_len'] = df.index.map(max_cds_len)\n",
    "df['txt_len'] = df.index.map(max_txt_len)\n",
    "df['gene_length'] = df.index.map(lambda x: db[x].end - db[x].start + 1)\n",
    "\n",
    "#df['log_tutr'] = df['tutr'].apply(np.log10)\n",
    "#df['log_futr'] = df['futr'].apply(np.log10)\n",
    "#df['log_txt'] = df['txt'].apply(np.log10)\n",
    "#df['log_gene'] = df['gene_length'].apply(np.log10)\n",
    "#log_df = df.replace([np.inf, -np.inf], np.nan).dropna(how='any')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abandoned-steal",
   "metadata": {},
   "source": [
    "#### Part II: Examine the UTR GC content and structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "colonial-cradle",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_txt_id(s):\n",
    "    '''This function is needed to extract the txt id for the CDS file'''\n",
    "    s2 = s.split('; ')\n",
    "    txt_id = list(filter(lambda x: x.startswith('parent'), s2))[0].split('=')[-1].split(',')[1]\n",
    "    return txt_id\n",
    "\n",
    "def parse_fb_fasta(infile, extract_ids=False):\n",
    "    if extract_ids:\n",
    "        txt_seqs = Fasta(infile, read_long_names=True, key_function=get_txt_id)\n",
    "    else:\n",
    "        txt_seqs = Fasta(infile)\n",
    "    return txt_seqs\n",
    "\n",
    "def count_gc(genelist, seq_dict, gene2txt):\n",
    "    gc_dict = {}\n",
    "    for i in genelist:\n",
    "        try:\n",
    "            longest_utr = seq_dict[gene2txt[i]][:].seq\n",
    "            gc_content = (longest_utr.count('G') + longest_utr.count('C'))/len(longest_utr)\n",
    "            gc_dict[i] = gc_content\n",
    "        except KeyError:\n",
    "            #keyError for non-coding RNAs\n",
    "            pass\n",
    "    return gc_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reverse-second",
   "metadata": {},
   "outputs": [],
   "source": [
    "futr_file = os.path.join(seqs_dir, 'five_prime_utr_all.fa')\n",
    "tutr_file = os.path.join(seqs_dir, 'three_prime_utr_all.fa')\n",
    "cds_file = os.path.join(seqs_dir, 'CDS_all.fa')\n",
    "futr_dict = parse_fb_fasta(futr_file)\n",
    "tutr_dict = parse_fb_fasta(tutr_file)\n",
    "cds_dict = parse_fb_fasta(cds_file, extract_ids=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "becoming-passport",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This script needs the transcript ID corresponding to the max length transcript\n",
    "tutr_gc = count_gc(df.index, tutr_dict, max_tutr_id)\n",
    "futr_gc = count_gc(df.index, futr_dict, max_futr_id)\n",
    "df['futr_gc'] = df.index.map(futr_gc)\n",
    "df['tutr_gc'] = df.index.map(tutr_gc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "understanding-transsexual",
   "metadata": {},
   "source": [
    "#### Part III: Add in the CAI values (see calc_CAI.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "downtown-shakespeare",
   "metadata": {},
   "outputs": [],
   "source": [
    "cai_file = os.path.join(outdir, 'CAI/CAI_values.csv')\n",
    "cai_df = pd.read_csv(cai_file, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accredited-enough",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(df, cai_df, left_index=True, right_index=True).to_csv(os.path.join(outdir, 'gene_attributes.csv'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('pretty')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "bdb49103a4ed208a05ea4530afbe53462c06fafea10c7833b005d674746fdb08"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
