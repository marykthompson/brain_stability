{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Motifs mir sites\n",
    "- Look at the transcript targets identified by Targetscan Fly v7.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import gffutils\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('../scripts/')\n",
    "from annotation_utilities import *\n",
    "from plot_helpers import *\n",
    "from scipy.stats import hypergeom\n",
    "from statsmodels.stats.multitest import fdrcorrection\n",
    "# from plotting_fxns import update_old_ids\n",
    "\n",
    "outdir = '../Figures/Motifs'\n",
    "os.makedirs(outdir, exist_ok = True)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract miRNA target predictions by gene\n",
    "- Use the miRNAs and context scores and context score percentiles from the \"Conserved_Site_Context_Scores\" file\n",
    "- Add the representative transcript and the PCT values from the \"Conserved_Family_Info\" file\n",
    "- Convert the IDs from 6.19 -> 6.28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# They used Flybase 6.19 = 2017_06\n",
    "gtf_file = '../../resources/other_studies/TargetScan/dmel-all-r6.19.gtf'\n",
    "db_out = '../../resources/other_studies/TargetScan/dmel_619.db'\n",
    "if not os.path.exists(db_out):\n",
    "    db = gffutils.create_db(gtf_file, db_out, disable_infer_genes = True, disable_infer_transcripts = True,\n",
    "    force = True, merge_strategy = 'create_unique')\n",
    "else:\n",
    "    db = gffutils.FeatureDB(db_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load TargetScan 7.2 Drosophila predictions, using representative transcripts for 6.19\n",
    "indir = '../../resources/other_studies/TargetScan/'\n",
    "cons_context_score_file = os.path.join(indir, 'Conserved_Site_Context_Scores.txt')\n",
    "cons_family_file = os.path.join(indir, 'Conserved_Family_Info.txt')\n",
    "\n",
    "# Family df has the representative txts and PCT values in it\n",
    "# context_score_df has the context scores and percentiles in it\n",
    "context_score_df = pd.read_csv(cons_context_score_file, sep='\\t').rename(columns={'UTR_start':'UTR start'})\n",
    "family_df = pd.read_csv(cons_family_file, sep='\\t').query('`Species ID` == 7227')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Focus on representative transcripts\n",
    "rep_txts = set(family_df['Transcript ID'].values)\n",
    "context_score_df = context_score_df.query('`Transcript ID` in @rep_txts').copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The PCT will be the same for all the families at the same site in the UTR because the sequences are the same\n",
    "family_df2 = family_df.drop_duplicates(subset=['Transcript ID', 'UTR start', 'UTR end'])\n",
    "# merge the PCT scores into the context score df\n",
    "df2 = pd.merge(context_score_df, family_df2[['Transcript ID', 'UTR start', 'UTR end', 'PCT']], left_on=['Transcript ID', 'UTR start', 'UTR end'], right_on=['Transcript ID', 'UTR start', 'UTR end'], how='left', indicator=True)\n",
    "context_score_only = len(df2.query('_merge == \"left_only\"'))\n",
    "both = len(df2.query('_merge == \"both\"'))\n",
    "print(f'% of context scores with no PCT {context_score_only*100/(context_score_only + both)}')\n",
    "# Some sites only have context score and no PCT. I assume this is because the PCT could not be calculated for these sites\n",
    "df2 = df2.query('_merge == \"both\"').copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the ID mapping table. The index is the old ID and the columns contain the newID\n",
    "id_dir = '../../resources/id_conversion/'\n",
    "# I don't know the annotation version used, so try to convert using the current ones\n",
    "dmel619_file = os.path.join(id_dir, 'fbgn_annotation_ID_fb_2017_06.tsv')\n",
    "dmel628_file = os.path.join(id_dir, 'fbgn_annotation_ID_fb_2019_03.tsv')\n",
    "cdf = update_ids(dmel628_file, dmel619_file, id_type='FB', genes=df2['Gene ID'].tolist())\n",
    "cdf.rename(columns={'new_ID':'gene_ID_628'}, inplace=True)\n",
    "df3 = pd.merge(df2, cdf[['gene_ID_628']], left_on='Gene ID', right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the PCT percentile by miRNA\n",
    "df3['PCT_percentile'] = df3.groupby('miRNA')['PCT'].transform('rank', pct=True)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that lower context score => higher percentile => better predicted targeting\n",
    "fig = plt.figure(figsize=(dfig,dfig))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.scatter(df3['weighted context++ score'], df3['weighted context++ score percentile'], color='k', alpha=0.1, s=1)\n",
    "ax.set_ylabel('percentile')\n",
    "ax.set_xlabel('weighted context++ score')\n",
    "# Check that high PCT => high percentile => better predicted targeting\n",
    "fig = plt.figure(figsize=(dfig,dfig))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.scatter(df3['PCT'], df3['PCT_percentile'], color='k', alpha=0.1, s=1)\n",
    "ax.set_ylabel('percentile')\n",
    "ax.set_xlabel('PCT')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find enrichment of miRNA sites in the TF RNAs\n",
    "- For each miRNA family: count occurences in bg group and subset (x/bg) vs. (y/subset)\n",
    "- Calculate enrichment with hypergeometric test\n",
    "- perform BH correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bg_genes = pd.read_csv(os.path.join(outdir,'bg_genes.csv'))['gene']\n",
    "subset_genes = pd.read_csv(os.path.join(outdir, 'CTS_TF_genes.csv'))['gene']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_mirs(df):\n",
    "    '''count mir hits by gene'''\n",
    "    mirs = df['miRNA'].unique()\n",
    "    mir_dict = {}\n",
    "    for mir in mirs:\n",
    "        mir_dict[mir] = {}\n",
    "        group_counts = len(df.query('miRNA == @mir&gene_ID_628 in @subset_genes'))\n",
    "        bg_counts = len(df.query('miRNA == @mir&gene_ID_628 in @bg_genes'))\n",
    "        mir_dict[mir]['subset'] = group_counts\n",
    "        mir_dict[mir]['bg'] = bg_counts\n",
    "\n",
    "    mir_df = pd.DataFrame.from_dict(mir_dict, orient='index')\n",
    "    N_bg = len(bg_genes)\n",
    "    N_subset = len(subset_genes)\n",
    "    mir_df['pval'] = mir_df.apply(lambda x: hypergeom.sf(x['subset']-1, N_bg, x['bg'], N_subset), axis=1)\n",
    "    rejected, p_adj = fdrcorrection(mir_df['pval'])\n",
    "    mir_df['pval_bh'] = p_adj\n",
    "    mir_df.sort_values(by='pval_bh', ascending=True, inplace=True)\n",
    "    return mir_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limit search to top 50% percentile for both PCT and context score\n",
    "df_50 = df3.query('PCT_percentile > 50&`weighted context++ score percentile` > 50').copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mir_df_50 = score_mirs(df_50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mir_df_50.head(n=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output a .gmt file to do GSEA analysis\n",
    "# Need targets for each miRNA set\n",
    "def write_mir_gmt(df, outname):\n",
    "    ''']\n",
    "    count mir hits by gene and write a .gmt file for GSEA\n",
    "    '''\n",
    "    mirs = df['miRNA'].unique()\n",
    "    mir_dict = {}\n",
    "    for mir in mirs:\n",
    "        mir_dict[mir] = df.query('miRNA == @mir&gene_ID_628 in @bg_genes')['Gene ID'].unique()\n",
    "\n",
    "    outfile = f'{outname}.gmt'\n",
    "    with open(outfile, 'w') as g:\n",
    "        for m in mir_dict:\n",
    "            setnames = f'{m}\\tna'\n",
    "            genes = '\\t'.join(mir_dict[m])\n",
    "            line = f'{setnames}\\t{genes}\\n'\n",
    "            g.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outname = os.path.join(outdir, 'miRNAs')\n",
    "mir_dict = write_mir_gmt(df_50, outname)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('pretty')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "bdb49103a4ed208a05ea4530afbe53462c06fafea10c7833b005d674746fdb08"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
