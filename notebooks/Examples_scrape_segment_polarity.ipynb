{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Example scrape segment polarity\n",
    "- Get the segment polarity genes from SBD online"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "# https://www.tutorialspoint.com/how-can-beautifulsoup-package-be-used-to-parse-data-from-a-webpage-in-python\n",
    "from urllib.request import urlopen, Request\n",
    "from urllib.error import HTTPError\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "sys.path.append('../scripts')\n",
    "from annotation_utilities import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_file = '../../resources/genelists/segment_polarity.html'\n",
    "\n",
    "outdir = '../Figures/Examples/'\n",
    "if not os.path.exists(outdir):\n",
    "    os.makedirs(outdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.geeksforgeeks.org/beautifulsoup-find-all-li-in-ul/\n",
    "# Getting the data via Request with 403 error\n",
    "# https://itsmycode.com/python-urllib-error-httperror-http-error-403-forbidden/\n",
    "# HTTPError: HTTP Error 404: Not Found\n",
    "parent_site = 'https://www.sdbonline.org/sites/fly/'\n",
    "soup = BeautifulSoup (open(table_file), \"html.parser\")\n",
    "# https://stackoverflow.com/questions/1080411/retrieve-links-from-web-page-using-python-and-beautifulsoup\n",
    "tables = soup.find_all('ul')\n",
    "genedict = {}\n",
    "# Beginning of section\n",
    "p = 0\n",
    "for pg in tables:\n",
    "    gene_pgs = pg.find_all('a')\n",
    "    # Each row is a different gene page, i.e. link to a gene page\n",
    "    for row in gene_pgs:\n",
    "        gene_ids = []\n",
    "        p += 1\n",
    "        name = row.text\n",
    "        if row['href'].startswith('http'):\n",
    "            link = row['href']\n",
    "            gene_id = link.split('/')[-1].rstrip('.html')\n",
    "            print('gene id', gene_id)\n",
    "        else:\n",
    "            link = os.path.join(parent_site, row['href'].lstrip('../'))\n",
    "            try:\n",
    "                req = Request(link, headers={'User-Agent': 'Mozilla/5.0'})\n",
    "                html = urlopen(req).read()\n",
    "                soup = BeautifulSoup(html, features=\"html.parser\")\n",
    "                result = soup.findAll('href', text=re.compile('FlyBase ID'))\n",
    "                first_sourceline = ''\n",
    "                for a in soup.find_all('a', href=True):\n",
    "                    sourceline = a.sourceline\n",
    "                    if 'flybase.org/reports' in a['href']:\n",
    "                        fb_id = a['href'].split('/')[-1].split('.')[0].strip()\n",
    "                        # First FBg on the page will be the one we want\n",
    "                        if first_sourceline == '':\n",
    "                            gene_ids.append(fb_id)\n",
    "                            first_sourceline = sourceline\n",
    "                        else:\n",
    "                            if (sourceline - first_sourceline) < 5:\n",
    "                                gene_ids.append(fb_id)\n",
    "            except HTTPError:\n",
    "                print(f'{name} not found')\n",
    "        # hash by FBg ID b/c these will be unique and names might not be unique\n",
    "        for g in gene_ids:\n",
    "            genedict[g] = name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manaully put this one in as Shank because the page was not found\n",
    "shank = 'FBgn0040752'\n",
    "sg_genes = set(list(genedict.keys()))\n",
    "sg_genes.add(shank)\n",
    "pd.DataFrame(sg_genes)[0].to_csv(os.path.join(outdir, 'segment_pol_genes_SBD.csv'), index=False, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the patterning genes and NB temporal genes\n",
    "# Manually look up the gene IDs in Flybase v6.32\n",
    "# This corresponse to the NB7-1 lineage, in fig. 1 of Doe review 2017\n",
    "embryo_nb = ['hb', 'svp', 'Kr', 'pdm2', 'nub', 'cas', 'grh']\n",
    "# These from the Syed & Doe eLife paper, 2017\n",
    "larval_nb = ['Imp', 'Syp', 'br', 'chinmo', 'Eip93F', 'svp', 'lin-28']\n",
    "# Additional ones from the Chris Doe review 2017\n",
    "extra_embryo_nb = ['sqz', 'nab']\n",
    "opc_nbs = ['hth', 'klu', 'ey', 'slp1', 'slp2', 'D', 'tll']\n",
    "topc_nbs = ['Dll', 'ey', 'slp1', 'slp2', 'D']\n",
    "mb_nbs = ['Imp', 'chinmo', 'Syp', 'br', 'mir-let7']\n",
    "ad_nbs = ['Imp', 'chinmo', 'Kr', 'Syp']\n",
    "thoracic_nbs = ['Imp', 'chinmo', 'cas', 'svp', 'Syp', 'br']\n",
    "typeII_nbs = ['cas', 'D', 'Imp', 'chinmo', 'lin-28', 'EcR', 'Syp', 'br', 'Eip93F']\n",
    "# pair-rule and gap genes reported by Interactive Fly\n",
    "# Classic set of pair-rule genes doesnt inclue Ten-m\n",
    "pairrule = ['eve', 'ftz', 'h', 'opa', 'odd', 'prd', 'runt', 'slp1', 'slp2', 'Ten-m']\n",
    "pairrule_classic = pairrule.remove('Ten-m')\n",
    "gap = ['btd', 'cnc', 'cad', 'kn', 'croc', 'ems', 'gt', 'hb', 'hkb', 'Kr', 'kni', 'oc', 'slp1', 'slp2', 'tll']\n",
    "\n",
    "genes = {'hb':'FBgn0001180', 'Kr':'FBgn0001325', 'pdm2':'FBgn0004394', 'cas':'FBgn0004878', 'eve':'FBgn0000606', 'ftz':'FBgn0001077', \n",
    "         'h':'FBgn0001168', 'opa':'FBgn0003002', 'odd':'FBgn0002985', 'prd':'FBgn0003145', 'runt':'FBgn0003300', 'slp2':'FBgn0004567', \n",
    "         'slp1':'FBgn0003430', 'Ten-m':'FBgn0004449', 'btd':'FBgn0000233', 'cnc':'FBgn0262975', 'cad':'FBgn0000251', 'kn':'FBgn0001319',\n",
    "         'croc':'FBgn0014143', 'ems':'FBgn0000576', 'gt':'FBgn0001150', 'hb':'FBgn0001180', 'hkb':'FBgn0261434', 'Kr':'FBgn0001325', \n",
    "         'kni':'FBgn0001320', 'oc':'FBgn0004102', 'tll':'FBgn0003720', 'Imp':'FBgn0285926', 'Syp':'FBgn0038826', 'nub':'FBgn0085424', \n",
    "         'grh':'FBgn0259211', 'br':'FBgn0283451', 'chinmo':'FBgn0086758', 'Eip93F':'FBgn0264490', 'svp':'FBgn0003651', 'lin-28':'FBgn0035626',\n",
    "         'sqz':'FBgn0010768', 'nab':'FBgn0259986', 'hth':'FBgn0001235', 'klu':'FBgn0013469', 'ey':'FBgn0005558', 'D':'FBgn0000411', 'tll':'FBgn0003720',\n",
    "         'Dll':'FBgn0000157','mir-let7':'FBgn0262406', 'EcR':'FBgn0000546'}\n",
    "\n",
    "all_nb_factors = [genes[i] for i in set(embryo_nb + extra_embryo_nb + larval_nb + opc_nbs + topc_nbs + mb_nbs + ad_nbs + thoracic_nbs + typeII_nbs)]\n",
    "all_pattern_factors = [genes[i] for i in set(pairrule + gap)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the ID mapping table. The index is the old ID and the columns contain the newID\n",
    "id_dir = '../../resources/id_conversion/'\n",
    "dmel632_file = os.path.join(id_dir, 'fbgn_annotation_ID_fb_2020_01.tsv')\n",
    "dmel628_file = os.path.join(id_dir, 'fbgn_annotation_ID_fb_2019_03.tsv')\n",
    "# Get the mapping between 628 -> 632\n",
    "cdf = update_ids(dmel632_file, dmel628_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used the Flybase ID validator v6.32 to validate IDs for the segment polarity genes\n",
    "# Remove ones from another species => current_symbol contains a backslash \\\n",
    "m = re.compile('\\\\\\\\')\n",
    "sp_df = pd.read_csv('../../resources/genelists/segpol_conversion_632.txt', sep='\\t')\n",
    "sp_df['nonDmel'] = sp_df['current_symbol'].apply(lambda x: True if m.search(x) else False)\n",
    "sp_df = sp_df.query('~nonDmel').copy()\n",
    "sp_df = sp_df.loc[sp_df['current_id'] != 'unknown ID'].copy()\n",
    "sp_df = sp_df.set_index('# submitted_id', drop=False)\n",
    "sp_df.index.name = 'index'\n",
    "sp_df = resolve_splits(sp_df, old_sym='# submitted_id', new_sym='current_symbol', new_ID='converted_id')\n",
    "# Check if any genes have been converted\n",
    "print(f'Genes after resolve split are equal to input genes: {sp_df.equals(sp_df)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdir2 = '../../resources/'\n",
    "cdf['seg_pol'] = cdf['new_ID'].isin(sp_df['current_id'])\n",
    "cdf['patterning'] = cdf['new_ID'].isin(all_pattern_factors)\n",
    "cdf['neuraldev'] = cdf['new_ID'].isin(all_nb_factors)\n",
    "pd.DataFrame(cdf.query('seg_pol').index).to_csv(os.path.join(outdir2, 'segpol_genes_628.csv'), index=False, header=False)\n",
    "pd.DataFrame(cdf.query('patterning').index).to_csv(os.path.join(outdir2, 'patterning_genes_628.csv'), index=False, header=False)\n",
    "pd.DataFrame(cdf.query('neuraldev').index).to_csv(os.path.join(outdir2, 'neuraldev_genes_628.csv'), index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that the most ones with two actually have two on the web\n",
    "from collections import Counter\n",
    "counter = Counter(genedict.values())\n",
    "counter.most_common()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('pretty')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "bdb49103a4ed208a05ea4530afbe53462c06fafea10c7833b005d674746fdb08"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
