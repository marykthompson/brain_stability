{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "younger-consolidation",
   "metadata": {},
   "source": [
    "### Prep test filters\n",
    "- Test filtering criteria to use for analysis cutoffs\n",
    "- Ideally removing these low abundance genes (basically dropouts in some libraries) will improve inter-replicate correlation.\n",
    "- Figure out what CPM corresponds to 10 counts as referenced by this post\n",
    "https://support.bioconductor.org/p/69433/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b9484f6",
   "metadata": {},
   "source": [
    "##### Conclusions\n",
    "- Choose genes with at least 10 counts in all libraries of one condition (input or pd), or in the BG3 case, input or pd, mutant or non mutant\n",
    "- For reproducibility scatter plot, it seems reasonable to further limit the comparison to genes with > 10 counts in the replicates being compared\n",
    "- We loose many genes by applying a degradation rate CV cutoff. In order to preserve N numbers for gene group comparisons, it seems resonable not to perform further filtering and to use all genes which pass the read count filtering\n",
    "- However, for the histogram in Fig. 1, where we are trying to estimate the decay rate and synthesis rate range, it seems reasonable to limit this to strictly 'high confidence' rates, in order to not over or under-estimate the range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "subtle-sunglasses",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import math\n",
    "import scipy.stats as stats\n",
    "import gffutils\n",
    "\n",
    "sys.path.append('../scripts')\n",
    "from plot_helpers import *\n",
    "from utilities import filter_low_exp, load_dataset, calc_pseudocount_val\n",
    "\n",
    "db = gffutils.FeatureDB(gffutils_db)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "educational-individual",
   "metadata": {},
   "source": [
    "#### Choice of filtering level for the experiments\n",
    "- Set the filtering level to 10 counts in at least 2/3 of libraries in one condition/replicate set\n",
    "- For most experimental sets, npass=2 because there were three replicates\n",
    "- For the ph/mock BG3 data, npass=4 for input mock because there were 6 replicates\n",
    "##### Another option would be to set filtering level to n counts in all libraries, and maybe that would solve the r2 dropout issue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "686819e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the genes passing the read count filtering for the each experiment\n",
    "outdir = '../Figures/summary_files'\n",
    "os.makedirs(outdir, exist_ok = True)\n",
    "\n",
    "#Exp1 (Brain4sU)\n",
    "res_file1 = os.path.join(results_dir, 'gene_quantification','summary_abundance_by_gene_filtered.csv')\n",
    "# Examine the following filters:\n",
    "# A) 10 counts in all libs of one condition\n",
    "# B) 10 counts in all\n",
    "# C) 1 CPM in in all libs of one condition\n",
    "# D) 1 CPM in all\n",
    "# Note that 1 CPM is up to 2X more than 10 counts for the brain library, but I feel that counts\n",
    "# is better to use because it's raw signal\n",
    "\n",
    "exp = [{'RNAtype':'input', 'condition':1, 'npass':3}, {'RNAtype':'pd', 'condition':1, 'npass':3}]\n",
    "\n",
    "passed_genes_A = filter_low_exp(res_file1, filter_co=10, filter_col='summed_est_counts', experiments=exp,\n",
    "                              outname=os.path.join(outdir,'brain4sU_10count_lib'))\n",
    "\n",
    "passed_genes_B = filter_low_exp(res_file1, filter_col='summed_est_counts', filter_co=10, npass=6,\n",
    "                              outname=os.path.join(outdir,'brain4sU_10count_all'))\n",
    "\n",
    "passed_genes_C = filter_low_exp(res_file1, filter_co=1, filter_col='CPM', experiments=exp,\n",
    "                              outname=os.path.join(outdir,'brain4sU_1cpm_lib'))\n",
    "\n",
    "passed_genes_D = filter_low_exp(res_file1, filter_col='CPM', filter_co=10, npass=6,\n",
    "                              outname=os.path.join(outdir,'brain4sU_1cpm_all'))\n",
    "\n",
    "print(f'co_10count_lib: {len(passed_genes_A)} passed the filter')\n",
    "print(f'co_10count_all: {len(passed_genes_B)} passed the filter')\n",
    "print(f'co_1cpm_lib: {len(passed_genes_C)} passed the filter')\n",
    "print(f'co_1cpm_all: {len(passed_genes_D)} passed the filter')\n",
    "# 1 CPM all causes a sharp decline from 8.7k genes for 10 counts per one condition to 3.7k genes for 1CPM all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b00c5db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_A = load_dataset(res_file1, os.path.join(outdir, 'brain4sU_10count_lib_passed.csv'))\n",
    "df_B = load_dataset(res_file1, os.path.join(outdir, 'brain4sU_10count_all_passed.csv'))\n",
    "df_C = load_dataset(res_file1, os.path.join(outdir, 'brain4sU_1cpm_lib_passed.csv'))\n",
    "df_D = load_dataset(res_file1, os.path.join(outdir, 'brain4sU_1cpm_all_passed.csv'))\n",
    "\n",
    "# Add CPM to these datasets since might need to filter further for the scatter plots:\n",
    "read_col = 'summed_est_counts'\n",
    "df_C['CPM'] = df_C[read_col]*1e6/df_C.groupby(['replicate', 'condition', 'RNAtype'])[read_col].transform('sum')\n",
    "df_D['CPM'] = df_D[read_col]*1e6/df_D.groupby(['replicate', 'condition', 'RNAtype'])[read_col].transform('sum')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e987f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotting_fxns import *\n",
    "def compare_plot(df, experiments=None, val_col=None, remove_low_count=None, ax=None, other_cols=[], low_count_val=-4):\n",
    "    '''\n",
    "    Wrapper to make comparison df and plot results.\n",
    "    '''\n",
    "    cdf = compare_experiments(df.reset_index(), experiments=experiments, id_col='gene', val_col=val_col, other_cols=other_cols, pseudo='min',\n",
    "                               log=True)\n",
    "    \n",
    "    if remove_low_count:\n",
    "        cdf = cdf.query(f'{remove_low_count}_x > {low_count_val} & {remove_low_count}_y > {low_count_val}')\n",
    "    ax = plot_scatter(cdf, experiments=[f'{val_col}_x', f'{val_col}_y'], id_col='gene', rsquare=True, ax=ax)\n",
    "    return cdf, ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1300a108",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make scatter plots without further filtering\n",
    "fig = plt.figure(figsize=(dfig*2,dfig*2), constrained_layout=True)\n",
    "ax1 = fig.add_subplot(221)\n",
    "ax2 = fig.add_subplot(222)\n",
    "ax3 = fig.add_subplot(223)\n",
    "ax4 = fig.add_subplot(224)\n",
    "cdf1, ax1 = compare_plot(df_A, experiments=[{'condition':1, 'RNAtype':'input', 'replicate':1}, \n",
    "                    {'condition':1, 'RNAtype':'input', 'replicate':2}], val_col = 'summed_tpm_recalc', \n",
    "                     ax=ax1)\n",
    "cdf2, ax2 = compare_plot(df_B, experiments=[{'condition':1, 'RNAtype':'input', 'replicate':1}, \n",
    "                    {'condition':1, 'RNAtype':'input', 'replicate':2}], val_col = 'summed_tpm_recalc', \n",
    "                     ax=ax2)\n",
    "cdf3, ax3 = compare_plot(df_C, experiments=[{'condition':1, 'RNAtype':'input', 'replicate':1}, \n",
    "                    {'condition':1, 'RNAtype':'input', 'replicate':2}], val_col = 'summed_tpm_recalc', \n",
    "                     ax=ax3)\n",
    "cdf4, ax4 = compare_plot(df_D, experiments=[{'condition':1, 'RNAtype':'input', 'replicate':1}, \n",
    "                    {'condition':1, 'RNAtype':'input', 'replicate':2}], val_col = 'summed_tpm_recalc', \n",
    "                     ax=ax4)\n",
    "\n",
    "axes = [ax1, ax2, ax3, ax4]\n",
    "for a in axes:\n",
    "    a.set_xlabel('rep1 TPM')\n",
    "    a.set_ylabel('rep2 TPM')\n",
    "ax1.text(0.1, 0.7, 'A', transform=ax1.transAxes)\n",
    "ax2.text(0.1, 0.7, 'B', transform=ax2.transAxes)\n",
    "ax3.text(0.1, 0.7, 'C', transform=ax3.transAxes)\n",
    "ax4.text(0.1, 0.7, 'D', transform=ax4.transAxes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "823266d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make scatter plots with further filtering to reach the cutoff in the libraries being commpared by plot\n",
    "fig = plt.figure(figsize=(dfig*2,dfig*2), constrained_layout=True)\n",
    "ax1 = fig.add_subplot(221)\n",
    "ax2 = fig.add_subplot(222)\n",
    "ax3 = fig.add_subplot(223)\n",
    "ax4 = fig.add_subplot(224)\n",
    "cdf1, ax1 = compare_plot(df_A, experiments=[{'condition':1, 'RNAtype':'input', 'replicate':1}, \n",
    "                    {'condition':1, 'RNAtype':'input', 'replicate':2}], val_col = 'summed_tpm_recalc', \n",
    "                     ax=ax1, remove_low_count='summed_est_counts', other_cols=['summed_est_counts'], \n",
    "                     low_count_val=10)\n",
    "cdf2, ax2 = compare_plot(df_B, experiments=[{'condition':1, 'RNAtype':'input', 'replicate':1}, \n",
    "                    {'condition':1, 'RNAtype':'input', 'replicate':2}], val_col = 'summed_tpm_recalc', \n",
    "                     ax=ax2, remove_low_count='summed_est_counts', other_cols=['summed_est_counts'], low_count_val=10)\n",
    "cdf3, ax3 = compare_plot(df_C, experiments=[{'condition':1, 'RNAtype':'input', 'replicate':1}, \n",
    "                    {'condition':1, 'RNAtype':'input', 'replicate':2}], val_col = 'summed_tpm_recalc', \n",
    "                     ax=ax3, remove_low_count='CPM', other_cols=['CPM'], low_count_val=1)\n",
    "cdf4, ax4 = compare_plot(df_D, experiments=[{'condition':1, 'RNAtype':'input', 'replicate':1}, \n",
    "                    {'condition':1, 'RNAtype':'input', 'replicate':2}], val_col = 'summed_tpm_recalc', \n",
    "                     ax=ax4, remove_low_count='CPM', other_cols=['CPM'], low_count_val=1)\n",
    "\n",
    "axes = [ax1, ax2, ax3, ax4]\n",
    "for a in axes:\n",
    "    a.set_xlabel('rep1 TPM')\n",
    "    a.set_ylabel('rep2 TPM')\n",
    "ax1.text(0.1, 0.7, 'A', transform=ax1.transAxes)\n",
    "ax2.text(0.1, 0.7, 'B', transform=ax2.transAxes)\n",
    "ax3.text(0.1, 0.7, 'C', transform=ax3.transAxes)\n",
    "ax4.text(0.1, 0.7, 'D', transform=ax4.transAxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d740c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now look at SD for decay rate of the different filtered genes:\n",
    "rate_df = pd.read_csv('../Figures/summary_files/INSPEcT_rates.csv', index_col='gene')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0128c28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "passed_A = set(pd.read_csv(os.path.join(outdir, 'brain4sU_10count_lib_passed.csv'), header=None)[0])\n",
    "passed_B = set(pd.read_csv(os.path.join(outdir, 'brain4sU_10count_all_passed.csv'), header=None)[0])\n",
    "passed_C = set(pd.read_csv(os.path.join(outdir, 'brain4sU_1cpm_lib_passed.csv'), header=None)[0])\n",
    "passed_D = set(pd.read_csv(os.path.join(outdir, 'brain4sU_1cpm_all_passed.csv'), header=None)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7607756c",
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_outdir = '../Figures/GEO_files/'\n",
    "rate_df = pd.read_csv(os.path.join(geo_outdir, 'INSPEcT_rates.csv'), index_col='gene_ID')\n",
    "rate_df_A = rate_df.loc[rate_df.index.isin(passed_A)].copy()\n",
    "rate_df_B = rate_df.loc[rate_df.index.isin(passed_B)].copy()\n",
    "rate_df_C = rate_df.loc[rate_df.index.isin(passed_C)].copy()\n",
    "rate_df_D = rate_df.loc[rate_df.index.isin(passed_D)].copy()\n",
    "\n",
    "for df in [rate_df_A, rate_df_B, rate_df_C, rate_df_D]:\n",
    "    df['log_deg_rate'] = df['degradation_rate'].apply(np.log10)\n",
    "    df['deg_CV'] = df['degradation_sd']*100/df['degradation_rate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2847c0ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram of the decay rates at various levels of filtering\n",
    "fig = plt.figure(figsize=(dfig,dfig))\n",
    "ax = fig.add_subplot(111)\n",
    "ax = sns.histplot(x='log_deg_rate', data=rate_df_A, label='deg_A', element='step', color=color_dict['grey'], fill=False, ax=ax)\n",
    "ax = sns.histplot(x='log_deg_rate', data=rate_df_B, label='deg_B', element='step', color=color_dict['blue'], fill=False, ax=ax)\n",
    "ax = sns.histplot(x='log_deg_rate', data=rate_df_C, label='deg_C', element='step', color=color_dict['purple'], fill=False, ax=ax)\n",
    "ax = sns.histplot(x='log_deg_rate', data=rate_df_D, label='deg_D', element='step', color=color_dict['green'], fill=False, ax=ax)\n",
    "ax.set_xlim(-5, 0)\n",
    "ax.legend()\n",
    "# More stringent filtering causes many of the very low decay rate genes to disappear\n",
    "# Low decay rate => present in the total, but very low counts in the PD. So these must be genes which were not detected in the pulldown libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce869026",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram of the decay rate CVs at various levels of filtering\n",
    "fig = plt.figure(figsize=(dfig,dfig))\n",
    "ax = fig.add_subplot(111)\n",
    "ax = sns.histplot(x='deg_CV', data=rate_df_A, label='deg_A', element='step', color=color_dict['grey'], fill=False, ax=ax)\n",
    "ax = sns.histplot(x='deg_CV', data=rate_df_B, label='deg_B', element='step', color=color_dict['blue'], fill=False, ax=ax)\n",
    "ax = sns.histplot(x='deg_CV', data=rate_df_C, label='deg_C', element='step', color=color_dict['purple'], fill=False, ax=ax)\n",
    "ax = sns.histplot(x='deg_CV', data=rate_df_D, label='deg_D', element='step', color=color_dict['green'], fill=False, ax=ax)\n",
    "# ax.set_xlim(-5, 0)\n",
    "ax.set_xlim(0, 200)\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a241bb22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is the relationship between CV and deg rates?\n",
    "fig = plt.figure(figsize=(dfig*2,dfig*2), constrained_layout=True)\n",
    "ax1 = fig.add_subplot(221)\n",
    "ax2 = fig.add_subplot(222)\n",
    "ax3 = fig.add_subplot(223)\n",
    "ax4 = fig.add_subplot(224)\n",
    "\n",
    "ax1 = sns.histplot(data=rate_df_A, x='log_deg_rate', y='deg_CV', cmap='rocket', ax=ax1, zorder=2)\n",
    "ax2 = sns.histplot(data=rate_df_B, x='log_deg_rate', y='deg_CV', cmap='rocket', ax=ax2, zorder=2)\n",
    "ax3 = sns.histplot(data=rate_df_C, x='log_deg_rate', y='deg_CV', cmap='rocket', ax=ax3, zorder=2)\n",
    "ax4 = sns.histplot(data=rate_df_D, x='log_deg_rate', y='deg_CV', cmap='rocket', ax=ax4, zorder=2)\n",
    "\n",
    "# ax1.scatter(rate_df_A['log_deg_rate'], rate_df_A['deg_CV'], s=1, color='k', alpha=0.1)\n",
    "# ax2.scatter(rate_df_B['log_deg_rate'], rate_df_B['deg_CV'], s=1, color='k', alpha=0.1)\n",
    "# ax3.scatter(rate_df_C['log_deg_rate'], rate_df_C['deg_CV'], s=1, color='k', alpha=0.1)\n",
    "# ax4.scatter(rate_df_D['log_deg_rate'], rate_df_D['deg_CV'], s=1, color='k', alpha=0.1)\n",
    "\n",
    "for ax in [ax1, ax2, ax3, ax4]:\n",
    "    ax.set_ylim(0, 200)\n",
    "    ax.set_xlim(-5, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20222cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering implications for SD of deg rates:\n",
    "# What is the median SD for each filtered set?\n",
    "# What fraction of read count/CPM filtered genes would pass the filter if CV set to cv_co?\n",
    "cv_co = 25\n",
    "dfs = {'A':rate_df_A, 'B':rate_df_B, 'C':rate_df_C, 'D':rate_df_D}\n",
    "\n",
    "for d in dfs:\n",
    "    print(f'{d} CV median {dfs[d][\"deg_CV\"].median()}')\n",
    "    print(f'frac passed CV co {len(dfs[d].query(\"deg_CV < @cv_co\"))/len(dfs[d])}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec01bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What happens to the histograms of synthesis and decay rates if we limit it to genes under certain CV cutoffs?\n",
    "cv_cos = [10, 25, 33, 50, 100]\n",
    "fig = plt.figure(figsize=(dfig*2, dfig), constrained_layout=True)\n",
    "ax = fig.add_subplot(111)\n",
    "sigma_deg = '%1.2f' % rate_df_A['log_deg_rate'].std()\n",
    "ax = sns.histplot(x='log_deg_rate', data=rate_df_A, label=f'none ({sigma_deg})', element='step', fill=False, ax=ax)\n",
    "for co in cv_cos:\n",
    "    this_df = rate_df_A.query('deg_CV <@co')\n",
    "    sigma_deg = '%1.2f' % this_df['log_deg_rate'].std()\n",
    "    ax = sns.histplot(x='log_deg_rate', data=this_df, label=f'{co} ({sigma_deg})', element='step', fill=False, ax=ax)\n",
    "ax.set_ylabel('number of genes')\n",
    "ax.legend()\n",
    "ax.set_xlim(-5, 3)\n",
    "plt.savefig('%s.%s' % (os.path.join(outdir, 'cvco_deg_hist'), out_fmt), dpi = out_dpi)\n",
    "# Conclusion: doesn't change a ton and no cutoff actually looks pretty similar to 10, so going to leave as is"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "200e45dc",
   "metadata": {},
   "source": [
    "Now figure out the percentile change vs. the deg rate CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a3a9b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "rate_df_A['stab_percentile'] = rate_df_A['halflife'].rank(pct=True)*100\n",
    "# https://stackoverflow.com/questions/55102473/how-do-we-fit-a-sigmoid-function-in-python\n",
    "# https://stackoverflow.com/questions/65233445/how-to-calculate-sums-in-log-space-without-underflow\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "def sigmoid (x, A, h, slope, C):\n",
    "    return 1 / (1 + np.exp ((x - h) / slope)) *  A + C\n",
    "\n",
    "p, _ = curve_fit(sigmoid, rate_df_A['degradation_rate'].apply(np.log10), rate_df_A['stab_percentile'])\n",
    "\n",
    "fig = plt.figure(figsize=(dfig,dfig))\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "x = rate_df_A['degradation_rate'].apply(np.log10)\n",
    "sorted_x = sorted(x)\n",
    "ax.scatter(x, rate_df_A['stab_percentile'], label='original')\n",
    "ax.plot(sorted_x, sigmoid(sorted_x, *p), label='sigmoid fit', color=color_dict['purple'])\n",
    "ax.legend()\n",
    "ax.set_xlim(-5,0)\n",
    "ax.set_xlabel('deg rate log'r'$_{10}$')\n",
    "ax.set_ylabel('stability percentile')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aefeff0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now calculate how much the stability percentile would change for given CV amounts\n",
    "test_df = rate_df_A[['degradation_rate', 'degradation_sd', 'deg_CV', 'stability_percentile']].copy()\n",
    "test_df['lower_linear'] = test_df['degradation_rate'] - test_df['degradation_sd']\n",
    "test_df['upper_linear'] = test_df['degradation_rate'] + test_df['degradation_sd']\n",
    "test_df[['log_deg_rate', 'log_deg_sd', 'log_lower', 'log_upper']] = test_df[['degradation_rate', 'degradation_sd', 'lower_linear', 'upper_linear']].apply(np.log10)\n",
    "test_df['lower_percentile'] = test_df['log_lower'].apply(lambda x: sigmoid(x, *p))\n",
    "test_df['upper_percentile'] = test_df['log_upper'].apply(lambda x: sigmoid(x, *p))\n",
    "test_df['percentile_spread'] = test_df['lower_percentile'] - test_df['upper_percentile']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45518cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_passed_genes(df, geneset=None, cv_co=[10, 25, 33, 50, 100]):\n",
    "    '''Find the number of genes in the df that pass at each CV cutoff'''\n",
    "    group_n = len(df.index.intersection(geneset))\n",
    "    # print(f'num genes with no cutoff {len(df.index.intersection(geneset))}')\n",
    "    d = {}\n",
    "    for i in cv_co:\n",
    "        genes = df.query('deg_CV <= @i').index\n",
    "        # print(f'co {i}: {len(genes.intersection(geneset))}')\n",
    "        d[i] = len(genes.intersection(geneset))/group_n\n",
    "    return pd.DataFrame.from_dict(d, orient='index')\n",
    "\n",
    "df = pd.read_csv('../Figures/Devreg/gene_cat_me3.csv', index_col='gene')\n",
    "df['me3'] = df['category'] == 'updowngene'\n",
    "\n",
    "me_df = find_passed_genes(test_df, geneset=df.query('me3').index)\n",
    "tf_df = find_passed_genes(test_df, geneset=df.query('TF').index)\n",
    "cts_df = find_passed_genes(test_df, geneset=df.query('CTS').index)\n",
    "all_df = find_passed_genes(test_df, geneset=df.index)\n",
    "\n",
    "frac_df = pd.concat([tf_df, me_df, cts_df, all_df], axis=1)\n",
    "frac_df.columns = ['TF', 'me3', 'CTS', 'all']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccef4895",
   "metadata": {},
   "outputs": [],
   "source": [
    "frac_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01810204",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['percentile_spread_higher?'] = test_df['percentile_spread'] > test_df['deg_CV']\n",
    "# Percentile spread is not higher than CV in any case:\n",
    "test_df['percentile_spread_higher?'].any()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37a50536",
   "metadata": {},
   "source": [
    "##### So what CV cutoff should we use?\n",
    "- Conservative: CV <10, gene would go from 10th percentile to 20th percentile\n",
    "- Moderate: CV < 25, gene would go from 10th percentile to 35th percentile\n",
    "- Liberal: CV < 33, gene would go from 10th percentile to 43rd percentile\n",
    "- How many TFs will pass at each threshold?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba1e411",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(dfig*2,dfig))\n",
    "ax1 = fig.add_subplot(121)\n",
    "ax2 = fig.add_subplot(122)\n",
    "\n",
    "ax1.scatter(test_df['deg_CV'], test_df['percentile_spread'], color='k', alpha=0.3, s=1)\n",
    "ax1.set_xlabel('deg CV')\n",
    "ax1.set_ylabel('percentile spread')\n",
    "ax2 = sns.histplot(data=test_df, x='deg_CV', y='percentile_spread', cmap='rocket', ax=ax2, zorder=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "409511f2",
   "metadata": {},
   "source": [
    "This shows that the CV is about equal to the percentile spread on average, but some genes have less percentile spread\n",
    "I'm thinking the ones that have less percentile spread might be genes that are closer to the edges, where larger quantitative changes \n",
    "don't have as large of an effect on the percentile (the sigmoid is flatter and less linear there)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61096799",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What about percentile vs. CV?\n",
    "fig = plt.figure(figsize=(dfig*2,dfig))\n",
    "ax1 = fig.add_subplot(121)\n",
    "# ax2 = fig.add_subplot(122)\n",
    "\n",
    "ax1.scatter(test_df['deg_CV'], test_df['stability_percentile'], color='k', alpha=0.3, s=1)\n",
    "# ax1.set_xlabel('deg CV')\n",
    "# ax1.set_ylabel('stability percentile')\n",
    "ax1.set_xlim(0,500)\n",
    "# ax2 = sns.histplot(data=test_df, x='deg_CV', y='stability_percentile', cmap='rocket', ax=ax2, zorder=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('pretty')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "bdb49103a4ed208a05ea4530afbe53462c06fafea10c7833b005d674746fdb08"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
